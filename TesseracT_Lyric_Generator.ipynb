{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TesseracT Lyric Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdAdETOKhdLP",
        "colab_type": "text"
      },
      "source": [
        "# TesseracT Lyric Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2UL1rmA_vNx",
        "colab_type": "code",
        "outputId": "6e682c52-109d-4626-f99e-acf184ad53a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!pip install markovify"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/de/c3/2e017f687e47e88eb9d8adf970527e2299fb566eba62112c2851ebb7ab93/markovify-0.8.0.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.8.0-cp36-none-any.whl size=10694 sha256=897614651c65865920b2e8a41f316d14af129455a9575280d52aca4a6fd4ba92\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/a8/92/35e2df870ff15a65657679dca105d190ec3c854a9f75435e40\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.8.0 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTrMtqeZz6GW",
        "colab_type": "code",
        "outputId": "511c668e-ea1d-4b81-fc58-0c527f8f5cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import re\n",
        "import spacy\n",
        "import markovify\n",
        "import warnings\n",
        "import nltk\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW7CKhGHg8bA",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBq3_HEmOKVR",
        "colab_type": "text"
      },
      "source": [
        "Inspired by the Text Generation checkpoint, I wanted to see what would happen if I input all the lyrics from my favorite progressive metal band, TesseracT. I copied and pasted all the lyrics into .txt files by hand, since there weren't too many to make it worth writing out a scraping algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8StY8csZhAOG",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning and exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAH3RT2UpRym",
        "colab_type": "text"
      },
      "source": [
        "Create a folder in this colab and name it \"tesseract\" and then put all the song lyric .txt files inside of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvoQtnWLHwQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DOC_PATTERN = r'.*\\.txt'\n",
        "corpus = PlaintextCorpusReader('/content/tesseract', DOC_PATTERN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIbMuCb7YixK",
        "colab_type": "code",
        "outputId": "5992b01b-0bb5-455c-fdf6-16f761bae7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO0zu8X-P2_Z",
        "colab_type": "text"
      },
      "source": [
        "When generating a song, I want to decide what is a good number of lines, or in the case of the corpus, sentences. So just dividing the number of sentences by the number of documents in the corpus will get the average number of lines in each song."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqODDCd4PMP5",
        "colab_type": "code",
        "outputId": "4f6b6ee0-465f-4153-bb39-ca325198cfb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(corpus.sents()) / len(corpus.fileids())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6SgEa_7QqXJ",
        "colab_type": "text"
      },
      "source": [
        "Join all the songs together as one long string for spaCy to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ahblQRwLMvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songs = [corpus.raw(fileid) for fileid in corpus.fileids()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oSQ6qpCMLmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songs = \" \".join(songs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx-aaTQ-gEK9",
        "colab_type": "text"
      },
      "source": [
        "Now to figure out the maximum characters per sentence by dividing the characters of all songs by the number of lines in all the songs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFHTcwFnUNMy",
        "colab_type": "code",
        "outputId": "294fd058-e49e-4563-d3c4-346d08db396d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(songs) / len(corpus.sents())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113.66917293233082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIDsIuXHgm5h",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the text data just in case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anCds3wqSeFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaner(text):\n",
        "    # visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  Better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9xW5aLXShq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songs = text_cleaner(songs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JY-7oIDrNtXW",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "songs = nlp(songs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOw0KV1krS2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDWYI2Zegruv",
        "colab_type": "text"
      },
      "source": [
        "Fusing it all back together into one string so markovify can make use of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHgdI2BKR4Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "song_lines = \" \".join([sent.text for sent in songs.sents if len(sent.text) > 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VIsL312nMTq",
        "colab_type": "text"
      },
      "source": [
        "# Converting to Numerical Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83xAKjZOnQZK",
        "colab_type": "text"
      },
      "source": [
        "Since my task involves markov chains and neural network-based text generation, I will not benefit from converting my data into numerical vectors. So I will skip straight to the text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zMpqmHqWAne",
        "colab_type": "text"
      },
      "source": [
        "# Generating Lyrics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV3-CwS7eoeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tesseract_generator(generator, num_lines, state_size, character_length):\n",
        "    markovifier = generator(song_lines, state_size = state_size)\n",
        "\n",
        "    return \"\\n\".join([markovifier.make_short_sentence(character_length) for i in range(num_lines)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSvVvMqNftWh",
        "colab_type": "text"
      },
      "source": [
        "## State Size = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNTEoEpTfi0n",
        "colab_type": "code",
        "outputId": "afb5655e-50ad-4c33-d93e-7cc73fe83b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(markovify.Text, 7, 3, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "Machinery dredge the sea All that's left is memory All the time they're suffering So when will it end?\n",
            "None\n",
            "None\n",
            "Run away from me Don't you come near with those eyes I hate them , why do they lie?\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChR7z70ckgXf",
        "colab_type": "text"
      },
      "source": [
        "## State Size = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCe1JsVNE3B",
        "colab_type": "code",
        "outputId": "ccfdf025-0448-40f1-a881-12aed5f75d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(markovify.Text, 7, 2, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Disturbed, when I get the feeling I've been chasing shadows Change.\n",
            "This structured raw submission, such a complex rage inside us all.\n",
            "All the time they lie to me I'm not to reprimand I'm here to help you through Is nothing like it seems?\n",
            "This structured raw submission, such a complex rage inside us all.\n",
            "This is another one of his ways To control me I feel dead inside Disturbed; will I fall?\n",
            "Will I disappear with a vision of her oh the feelings of pain And the vision of tomorrow Or will I fall?\n",
            "You walk through the furrows deep I sense the strain No one seems to know I can't feel the light?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKi-m4d3qCPA",
        "colab_type": "text"
      },
      "source": [
        "## State Size =1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5fIm5VbVngQ",
        "colab_type": "code",
        "outputId": "ef57b232-e809-4bdc-cbdf-c88b8366b2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(markovify.Text, 7, 1, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I won't be loved in Watching over Talking in mystery It seems to us, teary eyed History hexes us all.\n",
            "I'm full of pain And your waist lest you show?\n",
            "Don’t you sleep at me this sequence, a word of it costs All the prisoner You walk through the back of tomorrow?\n",
            "I so much we face a crevice in torn.\n",
            "We cannot forgive me?\n",
            "Take this world This structured raw submission, such a part of the world.\n",
            "History hexes us I feel the peace?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WkSXHp7WF9w",
        "colab_type": "text"
      },
      "source": [
        "Seems like the best state_size so far is 2. 3 doesn't seem to create much of anything original, just mashups of recognizable lines from existing songs, and 1 creates nonsense. But I'll see what the POSifiedText class from the checkpoint can do to improve things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPnocCcOeEJ1",
        "colab_type": "text"
      },
      "source": [
        "# POSified Lyric Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHAr65meDfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class POSifiedText(markovify.Text):\n",
        "    \n",
        "    def word_split(self, sentence):\n",
        "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
        "\n",
        "    def word_join(self, words):\n",
        "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
        "        return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcNnDF9Ympus",
        "colab_type": "text"
      },
      "source": [
        "## State Size = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTV3WNGymoIv",
        "colab_type": "code",
        "outputId": "6c8280e0-d8f5-4cce-97a8-ce0c02101cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(POSifiedText, 7, 3, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This structured raw submission , such a complex rage inside us all .\n",
            "I choose to never let go So take your time , prove your worth Do n't look .\n",
            "Machinery dredge the sea All that 's left is memory All the time they 're suffering So when will it end ?\n",
            "Disturbed , when I get the feeling I 've been chasing shadows Change .\n",
            "None\n",
            "This structured raw submission , such a complex rage inside us all .\n",
            "This structured raw submission , such a complex rage inside us all .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgG80KeBm0wl",
        "colab_type": "text"
      },
      "source": [
        "## State Size = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc-oJqoPm240",
        "colab_type": "code",
        "outputId": "9e76c22e-500b-484e-9067-f5907248dbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(POSifiedText, 7, 2, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Crawling through the crowd Lost in the sun You radiate for me And it all comes to life right before your eyes .\n",
            "You 're alive ; it 's too late ...\n",
            "Do n’t you know I ca n't feel whole ?\n",
            "Nascent , nascent , nascent , nascent , nascent , nascent .\n",
            "Nascent , nascent , nascent , nascent , nascent , nascent , nascent .\n",
            "Crawling through the wildest night Given to the sky .\n",
            "How will I fall ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-1OYJgtefoH",
        "colab_type": "text"
      },
      "source": [
        "## State Size = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3hD-GfIeTcO",
        "colab_type": "code",
        "outputId": "642e8e4f-254d-4be2-f238-fe06e027896c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "tesseract_generator(POSifiedText, 7, 1, 114)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The feelings we all But the storm I 'm a lie And now while I 'm still feel the sudden urges for you ’re feeling ?\n",
            "Do n't a child sleeping near his ways I know how you 'll be here before your hands and itinerant I long enough ?\n",
            "None\n",
            "Can we see Hopelessly I get the rules ...\n",
            "Do n't you 'll soothe you believe that you fall ?\n",
            "You trust me Do n't think Desperately opiate , such defiant menaces are born .\n",
            "Can you ; when will be ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Sow0O3oZyu",
        "colab_type": "text"
      },
      "source": [
        "Seems that state size of 2 is still the best, and this POSified class is a better version than without, just like in the checkpoint. \n",
        "\n",
        "Now this is all novel and all, but it has its limits, and doesn't play nicely with contractions. So, after reading about GPT-2 from OpenAI, I thought I would see what would happen after making use of it's model trained on 345 million text parameters, since it was the most easy to find an example to feed the lyrical data straight into, so I will clone N Shepperd's repo and run through his well written instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbRoY_ibbhKh",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2 345M Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICYu3w9hIJkC",
        "colab_type": "code",
        "outputId": "4f212334-f0b4-4073-cb31-f75f2ba0626a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 366, done.\u001b[K\n",
            "remote: Total 366 (delta 0), reused 0 (delta 0), pack-reused 366\u001b[K\n",
            "Receiving objects: 100% (366/366), 4.42 MiB | 15.71 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eEIs3ApZUVO",
        "colab_type": "code",
        "outputId": "d38f75cd-98f1-48fd-b158-1241137a7b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtn1qZPgZLb0",
        "colab_type": "text"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "434oOx0bZH6J",
        "colab_type": "code",
        "outputId": "bcc205f7-8f91-413f-a914-de20126fd316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.0MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=fedd6427fda8913bf81b06d4e79fa7a42c53650c5f35886ed7a9b4abd3860470\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533177 sha256=6efbc0904b9a8f946af6ea2d20669259ec10a4bdfd52d3641ee7bc390b40082c\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm, toposort\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5 toposort-1.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "regex",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzNKv2OFcEnZ",
        "colab_type": "code",
        "outputId": "9939cafb-f7a8-43d7-b977-aea9318c22a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvUQhgK3PQ4L",
        "colab_type": "text"
      },
      "source": [
        "Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNpf6R4ahYSN",
        "colab_type": "code",
        "outputId": "64244023-bb73-4aaa-d939-8116dd9174dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hrgeKFYsuE",
        "colab_type": "text"
      },
      "source": [
        "Download the model data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDpEGjfO8Q2",
        "colab_type": "code",
        "outputId": "be981660-13ba-4ac9-b9ef-3a3342229a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 1.19Mit/s]                                                     \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 52.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.28Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:17, 82.0Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 10.3Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 66.5Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 59.3Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq-YwRnNOBYO",
        "colab_type": "text"
      },
      "source": [
        "encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oJPQtdLbbeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzSbAvePgsI",
        "colab_type": "text"
      },
      "source": [
        "Fetch checkpoints if you have them saved in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA2Wk7yIPmS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/checkpoint/ /content/gpt-2/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfJ5b3CQXqr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Start training, add --model_name '345M' to use 345 model\n",
        "\n",
        "*Riley's additonal commentary:* For whatever text, lyrics or poetry you want your samples to be inspired by, input it as one long text file. I chose to format the separation of songs by two new lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEn_ihcGI00T",
        "colab_type": "code",
        "outputId": "fa4ac54b-27e9-4bf6-a279-b0102ae095c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset /content/gpt-2/all_lines.txt --model_name '345M'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-19 01:42:58.064016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-19 01:42:58.064226: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fcf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-19 01:42:58.064262: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-19 01:42:58.066326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-19 01:42:58.224577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.225297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fd100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-19 01:42:58.225328: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-01-19 01:42:58.225541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.226109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-19 01:42:58.226434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-19 01:42:58.228010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-19 01:42:58.232039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-19 01:42:58.232534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-19 01:42:58.234883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-19 01:42:58.236084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-19 01:42:58.240272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-19 01:42:58.240438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.241101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.241926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-19 01:42:58.242022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-19 01:42:58.243720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-19 01:42:58.243751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-19 01:42:58.243762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-19 01:42:58.243901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.244552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 01:42:58.245110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:89: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00, 3216.49it/s]\n",
            "dataset has 7670 tokens\n",
            "Training...\n",
            "2020-01-19 01:43:45.180272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "[1 | 11.47] loss=3.38 avg=3.38\n",
            "[2 | 12.97] loss=3.31 avg=3.34\n",
            "[3 | 14.46] loss=3.74 avg=3.48\n",
            "[4 | 15.96] loss=2.98 avg=3.35\n",
            "[5 | 17.46] loss=2.99 avg=3.28\n",
            "[6 | 18.96] loss=3.03 avg=3.24\n",
            "[7 | 20.46] loss=3.50 avg=3.27\n",
            "[8 | 21.97] loss=3.03 avg=3.24\n",
            "[9 | 23.49] loss=3.22 avg=3.24\n",
            "[10 | 25.00] loss=3.38 avg=3.26\n",
            "[11 | 26.52] loss=2.81 avg=3.21\n",
            "[12 | 28.03] loss=2.86 avg=3.18\n",
            "[13 | 29.55] loss=3.33 avg=3.19\n",
            "[14 | 31.07] loss=3.00 avg=3.18\n",
            "[15 | 32.60] loss=2.90 avg=3.16\n",
            "[16 | 34.12] loss=2.77 avg=3.13\n",
            "[17 | 35.65] loss=2.85 avg=3.11\n",
            "[18 | 37.18] loss=3.17 avg=3.12\n",
            "[19 | 38.72] loss=3.37 avg=3.13\n",
            "[20 | 40.25] loss=2.94 avg=3.12\n",
            "[21 | 41.79] loss=2.73 avg=3.10\n",
            "[22 | 43.33] loss=2.81 avg=3.09\n",
            "[23 | 44.87] loss=2.83 avg=3.07\n",
            "[24 | 46.41] loss=3.25 avg=3.08\n",
            "[25 | 47.96] loss=3.05 avg=3.08\n",
            "[26 | 49.51] loss=2.95 avg=3.08\n",
            "[27 | 51.06] loss=2.65 avg=3.06\n",
            "[28 | 52.61] loss=2.76 avg=3.05\n",
            "[29 | 54.17] loss=2.49 avg=3.02\n",
            "[30 | 55.72] loss=2.55 avg=3.01\n",
            "[31 | 57.28] loss=2.53 avg=2.99\n",
            "[32 | 58.84] loss=3.07 avg=2.99\n",
            "[33 | 60.41] loss=2.68 avg=2.98\n",
            "[34 | 61.97] loss=2.50 avg=2.96\n",
            "[35 | 63.54] loss=2.93 avg=2.96\n",
            "[36 | 65.10] loss=2.96 avg=2.96\n",
            "[37 | 66.67] loss=2.89 avg=2.96\n",
            "[38 | 68.24] loss=2.93 avg=2.96\n",
            "[39 | 69.82] loss=2.33 avg=2.94\n",
            "[40 | 71.39] loss=2.51 avg=2.93\n",
            "[41 | 72.97] loss=2.47 avg=2.91\n",
            "[42 | 74.55] loss=2.55 avg=2.90\n",
            "[43 | 76.14] loss=2.53 avg=2.89\n",
            "[44 | 77.73] loss=2.73 avg=2.89\n",
            "[45 | 79.32] loss=2.44 avg=2.88\n",
            "[46 | 80.92] loss=2.37 avg=2.86\n",
            "[47 | 82.52] loss=2.36 avg=2.85\n",
            "[48 | 84.12] loss=2.32 avg=2.83\n",
            "[49 | 85.72] loss=2.17 avg=2.82\n",
            "[50 | 87.32] loss=2.19 avg=2.80\n",
            "[51 | 88.93] loss=2.28 avg=2.79\n",
            "[52 | 90.54] loss=2.23 avg=2.77\n",
            "[53 | 92.15] loss=2.22 avg=2.76\n",
            "[54 | 93.78] loss=2.12 avg=2.75\n",
            "[55 | 95.40] loss=2.07 avg=2.73\n",
            "[56 | 97.02] loss=2.07 avg=2.71\n",
            "[57 | 98.65] loss=2.12 avg=2.70\n",
            "[58 | 100.28] loss=2.16 avg=2.69\n",
            "[59 | 101.91] loss=2.61 avg=2.69\n",
            "[60 | 103.54] loss=1.95 avg=2.67\n",
            "[61 | 105.18] loss=1.83 avg=2.65\n",
            "[62 | 106.82] loss=2.10 avg=2.64\n",
            "[63 | 108.47] loss=2.05 avg=2.63\n",
            "[64 | 110.12] loss=1.62 avg=2.61\n",
            "[65 | 111.78] loss=1.64 avg=2.59\n",
            "[66 | 113.42] loss=1.70 avg=2.57\n",
            "[67 | 115.07] loss=1.92 avg=2.56\n",
            "[68 | 116.72] loss=1.90 avg=2.54\n",
            "[69 | 118.37] loss=1.70 avg=2.53\n",
            "[70 | 120.03] loss=1.76 avg=2.51\n",
            "[71 | 121.68] loss=2.23 avg=2.50\n",
            "[72 | 123.34] loss=2.33 avg=2.50\n",
            "[73 | 125.01] loss=1.61 avg=2.48\n",
            "[74 | 126.68] loss=1.60 avg=2.47\n",
            "[75 | 128.36] loss=1.62 avg=2.45\n",
            "[76 | 130.04] loss=1.48 avg=2.43\n",
            "[77 | 131.72] loss=1.85 avg=2.42\n",
            "[78 | 133.41] loss=2.03 avg=2.41\n",
            "[79 | 135.10] loss=1.83 avg=2.40\n",
            "[80 | 136.79] loss=1.29 avg=2.38\n",
            "[81 | 138.49] loss=1.82 avg=2.37\n",
            "[82 | 140.19] loss=1.77 avg=2.36\n",
            "[83 | 141.90] loss=1.44 avg=2.35\n",
            "[84 | 143.60] loss=1.26 avg=2.33\n",
            "[85 | 145.32] loss=1.01 avg=2.30\n",
            "[86 | 147.02] loss=1.15 avg=2.28\n",
            "[87 | 148.73] loss=1.48 avg=2.27\n",
            "[88 | 150.46] loss=1.45 avg=2.26\n",
            "[89 | 152.19] loss=1.36 avg=2.24\n",
            "[90 | 153.92] loss=1.37 avg=2.23\n",
            "[91 | 155.66] loss=1.26 avg=2.21\n",
            "[92 | 157.41] loss=1.07 avg=2.19\n",
            "[93 | 159.15] loss=0.84 avg=2.17\n",
            "[94 | 160.89] loss=0.75 avg=2.15\n",
            "[95 | 162.64] loss=1.22 avg=2.13\n",
            "[96 | 164.38] loss=0.83 avg=2.11\n",
            "[97 | 166.14] loss=0.78 avg=2.09\n",
            "[98 | 167.90] loss=1.29 avg=2.08\n",
            "[99 | 169.64] loss=0.94 avg=2.06\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " and will continue to work to secure it.\"\n",
            "\n",
            "He said the Department for Communities and Local Government had made \"serious progress\" under the coalition and was committed to keeping its key domestic programmes under its control by 2018.\n",
            "\n",
            "Media playback is unsupported on your device Media caption Jeremy Corbyn: \"The Tories have no plan\"\n",
            "\n",
            "The Conservatives' last budget, cut funding to key housing and social care projects.\n",
            "Joint Liberal Democrat and Tory parties pledged to continue their cuts in social care and domestic social security.\n",
            "Labour said Labour's plans would mean an estimated £4bn of cuts across government and communities.\n",
            "\n",
            "'More work to do'\n",
            "The chancellor has told the BBC that his \"commitment\" was to the coalition\n",
            "He said the next Labour government would bring real stability to government\n",
            "Mr Corbyn said: \"This government have put the economy first - but not once have I said they should take away people's money, especially in the last recession.\"\n",
            "He said the policies of the Conservatives meant millions could lose £4bn a year.\n",
            "He added: \"They are cutting people's benefits, they are denying them the chance to buy a home that will make them more independent and fulfil their dreams.\n",
            "\"This is the record of an adulteurer who has reduced our resources for the future and made it more likely that millions of people will live in poverty on the day they die.\n",
            "\"This is not about the past. It is about the future.\"\n",
            "Analysis\n",
            "By Brian Taylor, health correspondent\n",
            "As I write this my son is having a gastric tube operation from our failure to give him a chance\n",
            "The Conservatives say their record on public spending will be the basis of government.\n",
            "A government which will reduce the deficit. A government which will provide relief to the people of this country. A government which will restore stability and security to our streets, lift families into the light and transform our lives.\n",
            "All of this they have promised - but the fact is that in its present form, the Budget is a colossal dud.\n",
            "It contains the cuts announced in the Queen's Speech.\n",
            "It includes the huge tax rises announced in the Budget on Tuesday evening.\n",
            "It also scraps the plans for affordable homes introduced by Nick Clegg, who now promises he will renegotiate the terms of the next few years.\n",
            "It also leaves more than a million people without affordable homes - but the Tories will not guarantee that the extra money is always spent on the people who need it the most.\n",
            "The Prime Minister is promising to provide the stability and security the country so desperately needs.\n",
            "No. She is promising to break the back of the people who need it the most.\n",
            "Media playback is unsupported on your device Media caption Labour leader Ed Miliband says Labour \"won't govern by fear\"\n",
            "Labour's manifesto, published alongside the Tories' manifesto, will make cuts to the public services the country needs\n",
            "It promises an end to national insurance, the right to private health insurance, cuts to housing benefit payments and increases in benefit for those with children.\n",
            "It pledges to protect the NHS against a Labour government, but it won't guarantee a future Conservative government will match the pledges to make our NHS fairer and more efficient.\n",
            "The Tories' \"hard Brexit\" will cost our economy more than it's worth\n",
            "A series of tax and spending policies - not all of them fair - will see the total cost of Labour's programme for Britain to the rest of the world rise by £1.1tn.\n",
            "And that is not counting the money that the Tories are refusing to spend.\n",
            "For seven years they've been promising more taxes and spending. And now they've got it all.\n",
            "The economy won't be the same; jobs won't come back; schools won't be ready for the first time.\n",
            "The future won't be what it's going to be.\n",
            "How do we turn this planet into a family?\n",
            "A new spirit of hope will sweep across the land\n",
            "A new pride will sweep through our lives\n",
            "Will we be the people we were made for?\n",
            "By the light of the sun\n",
            "The promise of a brighter tomorrow\n",
            "A vision of a better life...\n",
            "\n",
            "All promise and none of the sudden\n",
            "\n",
            "The night is dark and stormy\n",
            "All promise and none of the sudden\n",
            "The storm that broke the king's back\n",
            "All hope is dead\n",
            "Will we trust in the invisible hand\n",
            "That it will mend our broken backs?\n",
            "I'm not a prophet\n",
            "And you're not a healer\n",
            "All this talk of reform and transformation\n",
            "Well I tell you what I know\n",
            "The sun will rise again\n",
            "And the moon will lie down under our feet\n",
            "\n",
            "\n",
            "I won't dance because you don't like it\n",
            "Garden gnarled, ivy fallen\n",
            "No patience, no understanding\n",
            "I swear, I'm insane\n",
            "\n",
            "Will we now all just live peacefully with our minds\n",
            "Or will we?\n",
            "No, this isn't the America of my dreams\n",
            "I'm a failure\n",
            "The\n",
            "\n",
            "[100 | 195.92] loss=0.67 avg=2.04\n",
            "[101 | 197.65] loss=0.57 avg=2.01\n",
            "[102 | 199.37] loss=0.78 avg=1.99\n",
            "[103 | 201.09] loss=0.57 avg=1.97\n",
            "[104 | 202.82] loss=1.20 avg=1.96\n",
            "[105 | 204.53] loss=0.50 avg=1.94\n",
            "[106 | 206.26] loss=0.73 avg=1.92\n",
            "[107 | 207.98] loss=0.82 avg=1.90\n",
            "[108 | 209.70] loss=0.40 avg=1.88\n",
            "[109 | 211.42] loss=0.35 avg=1.86\n",
            "[110 | 213.14] loss=0.70 avg=1.84\n",
            "[111 | 214.86] loss=0.29 avg=1.82\n",
            "[112 | 216.59] loss=1.07 avg=1.81\n",
            "[113 | 218.31] loss=0.76 avg=1.79\n",
            "[114 | 220.05] loss=0.81 avg=1.78\n",
            "[115 | 221.79] loss=0.49 avg=1.76\n",
            "[116 | 223.52] loss=0.64 avg=1.74\n",
            "[117 | 225.25] loss=0.35 avg=1.72\n",
            "[118 | 226.98] loss=0.59 avg=1.70\n",
            "[119 | 228.72] loss=0.66 avg=1.69\n",
            "[120 | 230.45] loss=0.54 avg=1.67\n",
            "[121 | 232.20] loss=0.48 avg=1.66\n",
            "[122 | 233.94] loss=1.20 avg=1.65\n",
            "[123 | 235.69] loss=0.36 avg=1.63\n",
            "[124 | 237.43] loss=0.38 avg=1.61\n",
            "[125 | 239.17] loss=0.19 avg=1.59\n",
            "[126 | 240.91] loss=0.27 avg=1.58\n",
            "[127 | 242.65] loss=0.41 avg=1.56\n",
            "[128 | 244.42] loss=0.31 avg=1.54\n",
            "[129 | 246.16] loss=0.41 avg=1.53\n",
            "[130 | 247.90] loss=0.48 avg=1.51\n",
            "[131 | 249.65] loss=0.22 avg=1.49\n",
            "[132 | 251.40] loss=0.65 avg=1.48\n",
            "[133 | 253.17] loss=0.30 avg=1.47\n",
            "[134 | 254.93] loss=0.78 avg=1.46\n",
            "[135 | 256.70] loss=0.53 avg=1.45\n",
            "[136 | 258.45] loss=0.22 avg=1.43\n",
            "[137 | 260.20] loss=0.24 avg=1.41\n",
            "[138 | 261.96] loss=0.42 avg=1.40\n",
            "[139 | 263.70] loss=0.21 avg=1.38\n",
            "[140 | 265.47] loss=0.23 avg=1.37\n",
            "[141 | 267.21] loss=0.38 avg=1.36\n",
            "[142 | 268.95] loss=0.61 avg=1.35\n",
            "[143 | 270.71] loss=0.24 avg=1.33\n",
            "[144 | 272.47] loss=0.20 avg=1.32\n",
            "[145 | 274.23] loss=0.14 avg=1.30\n",
            "[146 | 275.99] loss=0.21 avg=1.29\n",
            "[147 | 277.75] loss=0.27 avg=1.27\n",
            "[148 | 279.51] loss=0.13 avg=1.26\n",
            "[149 | 281.26] loss=0.12 avg=1.24\n",
            "[150 | 283.02] loss=0.10 avg=1.23\n",
            "[151 | 284.76] loss=0.25 avg=1.22\n",
            "[152 | 286.48] loss=0.16 avg=1.20\n",
            "[153 | 288.23] loss=0.15 avg=1.19\n",
            "[154 | 289.97] loss=1.13 avg=1.19\n",
            "[155 | 291.71] loss=0.26 avg=1.18\n",
            "[156 | 293.46] loss=0.19 avg=1.17\n",
            "[157 | 295.20] loss=0.18 avg=1.15\n",
            "[158 | 296.96] loss=0.08 avg=1.14\n",
            "[159 | 298.73] loss=0.16 avg=1.13\n",
            "[160 | 300.49] loss=0.22 avg=1.12\n",
            "[161 | 302.23] loss=0.11 avg=1.10\n",
            "[162 | 303.99] loss=0.13 avg=1.09\n",
            "[163 | 305.75] loss=0.07 avg=1.08\n",
            "[164 | 307.50] loss=0.38 avg=1.07\n",
            "[165 | 309.22] loss=0.13 avg=1.06\n",
            "[166 | 310.98] loss=0.20 avg=1.05\n",
            "[167 | 312.72] loss=0.17 avg=1.04\n",
            "[168 | 314.46] loss=0.12 avg=1.03\n",
            "[169 | 316.23] loss=0.13 avg=1.01\n",
            "[170 | 317.99] loss=0.13 avg=1.00\n",
            "[171 | 319.72] loss=0.21 avg=0.99\n",
            "[172 | 321.45] loss=0.14 avg=0.98\n",
            "[173 | 323.22] loss=0.07 avg=0.97\n",
            "[174 | 324.96] loss=0.11 avg=0.96\n",
            "[175 | 326.71] loss=0.06 avg=0.95\n",
            "[176 | 328.46] loss=0.11 avg=0.94\n",
            "[177 | 330.19] loss=0.09 avg=0.93\n",
            "[178 | 331.96] loss=0.08 avg=0.92\n",
            "[179 | 333.72] loss=0.13 avg=0.91\n",
            "[180 | 335.46] loss=0.14 avg=0.90\n",
            "[181 | 337.20] loss=0.17 avg=0.89\n",
            "[182 | 338.95] loss=0.09 avg=0.88\n",
            "[183 | 340.69] loss=0.13 avg=0.87\n",
            "[184 | 342.45] loss=0.08 avg=0.86\n",
            "[185 | 344.21] loss=0.10 avg=0.86\n",
            "[186 | 345.95] loss=0.09 avg=0.85\n",
            "[187 | 347.70] loss=0.11 avg=0.84\n",
            "[188 | 349.44] loss=0.12 avg=0.83\n",
            "[189 | 351.20] loss=0.06 avg=0.82\n",
            "[190 | 352.94] loss=0.10 avg=0.81\n",
            "[191 | 354.71] loss=0.07 avg=0.80\n",
            "[192 | 356.47] loss=0.08 avg=0.79\n",
            "[193 | 358.22] loss=0.06 avg=0.79\n",
            "[194 | 359.98] loss=0.12 avg=0.78\n",
            "[195 | 361.72] loss=0.07 avg=0.77\n",
            "[196 | 363.48] loss=0.17 avg=0.76\n",
            "[197 | 365.23] loss=0.53 avg=0.76\n",
            "[198 | 366.97] loss=0.10 avg=0.75\n",
            "[199 | 368.71] loss=0.13 avg=0.75\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " lips I can taste of your precum pressing into my slit. Your strong arms wrap around me as we kiss. Your body heat radiates off of me as we spend the rest of the evening together.\n",
            "\n",
            "I could take you to every fantasy\n",
            "I create\n",
            "Dream big and strive\n",
            "The dragon lays dreaming\n",
            "Give him rest in his lethargy\n",
            "Give him all you know\n",
            "With love and tenderness\n",
            "\n",
            "Here I can finally breathe\n",
            "I need you inside of me\n",
            "\n",
            "I need you inside of me\n",
            "\n",
            "I'm so close. I'm so close.\n",
            "\n",
            "Lightning flashes for a moment before vanishing\n",
            "Time slows to a crawl\n",
            "Dead silence. A hand slides up from behind\n",
            "Fear grips at my sides.\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "Dead silence. A hand slides up from behind\n",
            "Fear grips at my sides.\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "A hand slides up from under my chin\n",
            "Dead silence. A hand slides up from under my chin\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "Dead silence.\n",
            "Hand slides up from under my chin\n",
            "Dead silence.\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "A hand slides up from under my chin\n",
            "Dead silence.\n",
            "Dead silence.\n",
            "A hand slides up from under my chin\n",
            "Dead silence.\n",
            "Lightning flashes for a moment before vanishing\n",
            "Dead silence.\n",
            "A hand slides up from under my chin\n",
            "Dead silence.\n",
            "Dead silence.\n",
            "\n",
            "\n",
            "Don't you look at me with those eyes\n",
            "I doubt you'll ever walk through them\n",
            "I'm talking to myself\n",
            "I'm talking to myself\n",
            "I'm not worthy\n",
            "\n",
            "Of life\n",
            "I doubt you'll ever walk through them\n",
            "\n",
            "I'm talking to myself\n",
            "I'm talking to myself\n",
            "I'm not worthy\n",
            "\n",
            "Of life\n",
            "I doubt you'll ever walk through them\n",
            "\n",
            "I'm talking to myself\n",
            "I'm talking to myself\n",
            "I'm not worthy\n",
            "Of life\n",
            "\n",
            "\n",
            "Is everything all it seems like it is?\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "(It's not the end of the journey)\n",
            "(It's not the end of the journey)\n",
            "\n",
            "Turn your back on everything\n",
            "Last man standing\n",
            "Keep trying, keep trying\n",
            "Life is never fair\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "It's not the end of the journey\n",
            "\n",
            "\n",
            "No patience, no understanding\n",
            "All the time they lie to me\n",
            "I suffer in silence\n",
            "A rift in time\n",
            "\n",
            "No friendship, no love\n",
            "\n",
            "Gather 'round to the sound of love\n",
            "Jolts of insight\n",
            "We find\n",
            "Sweet relief of perspective\n",
            "\n",
            "On to the other side\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "To the other side\n",
            "\n",
            "\n",
            "You could raise the dead\n",
            "With these lips\n",
            "We're so different\n",
            "Living under his wing\n",
            "Making mistakes in private\n",
            "Won't you forget\n",
            "Are you the type who\n",
            "Lies to yourself?\n",
            "\n",
            "I can't believe that you're willing\n",
            "To try\n",
            "Won't you take a chance?\n",
            "\n",
            "Am I to think otherwise?\n",
            "\n",
            "Will I change my mind?\n",
            "Victor T | C | L 18\n",
            "\n",
            "False start, false start\n",
            "You're dead inside\n",
            "Can't you see the pattern\n",
            "I'm letting go\n",
            "It's a-gonna be some grand finale\n",
            "\n",
            "Empty lungs, empty heart\n",
            "\n",
            "Let's hope no one's beneath our feet\n",
            "\n",
            "Let's hope no one's beneath our feet\n",
            "\n",
            "Let's hope no one's beneath our feet\n",
            "\n",
            "\n",
            "Will I change my mind?\n",
            "I'll walk through the woods\n",
            "With a clear mind\n",
            "Won't I be a better photographer\n",
            "than I was before?\n",
            "\n",
            "What's the confliction between good and evil\n",
            "That riles deep within\n",
            "In the back of our minds\n",
            "\n",
            "It seems we evolve\n",
            "Evolve\n",
            "Evolve\n",
            "\n",
            "Evolve\n",
            "\n",
            "Evolve\n",
            "\n",
            "\n",
            "I will take a bullet for you\n",
            "I will take a bullet for you\n",
            "I will take a bullet for you\n",
            "I will take a bullet for you\n",
            "\n",
            "I will take a bullet for you\n",
            "\n",
            "\n",
            "When I am threatened\n",
            "I become a monster\n",
            "And you'll find me\n",
            "Scuttling about\n",
            "Sprinting through the grass\n",
            "\n",
            "[200 | 392.09] loss=0.05 avg=0.74\n",
            "[201 | 393.80] loss=0.09 avg=0.73\n",
            "[202 | 395.53] loss=0.22 avg=0.72\n",
            "[203 | 397.25] loss=0.19 avg=0.72\n",
            "[204 | 398.99] loss=0.09 avg=0.71\n",
            "[205 | 400.71] loss=0.03 avg=0.70\n",
            "[206 | 402.43] loss=0.04 avg=0.70\n",
            "[207 | 404.16] loss=0.06 avg=0.69\n",
            "[208 | 405.88] loss=0.13 avg=0.68\n",
            "[209 | 407.61] loss=0.05 avg=0.68\n",
            "[210 | 409.34] loss=0.07 avg=0.67\n",
            "[211 | 411.07] loss=0.07 avg=0.66\n",
            "[212 | 412.79] loss=0.09 avg=0.65\n",
            "[213 | 414.53] loss=0.14 avg=0.65\n",
            "[214 | 416.27] loss=0.05 avg=0.64\n",
            "[215 | 417.99] loss=0.07 avg=0.64\n",
            "[216 | 419.72] loss=0.08 avg=0.63\n",
            "[217 | 421.45] loss=0.06 avg=0.62\n",
            "[218 | 423.19] loss=0.06 avg=0.62\n",
            "[219 | 424.93] loss=0.06 avg=0.61\n",
            "[220 | 426.67] loss=0.07 avg=0.60\n",
            "[221 | 428.42] loss=0.10 avg=0.60\n",
            "[222 | 430.16] loss=0.05 avg=0.59\n",
            "[223 | 431.90] loss=0.06 avg=0.59\n",
            "[224 | 433.65] loss=0.08 avg=0.58\n",
            "[225 | 435.39] loss=0.11 avg=0.58\n",
            "[226 | 437.13] loss=0.07 avg=0.57\n",
            "[227 | 438.88] loss=0.05 avg=0.56\n",
            "[228 | 440.62] loss=0.11 avg=0.56\n",
            "[229 | 442.36] loss=0.11 avg=0.55\n",
            "[230 | 444.10] loss=0.04 avg=0.55\n",
            "[231 | 445.86] loss=0.05 avg=0.54\n",
            "[232 | 447.62] loss=0.08 avg=0.54\n",
            "[233 | 449.37] loss=0.07 avg=0.53\n",
            "[234 | 451.13] loss=0.07 avg=0.53\n",
            "[235 | 452.89] loss=0.07 avg=0.52\n",
            "[236 | 454.64] loss=0.05 avg=0.52\n",
            "[237 | 456.38] loss=0.11 avg=0.51\n",
            "[238 | 458.12] loss=0.05 avg=0.51\n",
            "[239 | 459.88] loss=0.08 avg=0.50\n",
            "[240 | 461.63] loss=0.36 avg=0.50\n",
            "[241 | 463.39] loss=0.03 avg=0.50\n",
            "[242 | 465.14] loss=0.14 avg=0.49\n",
            "[243 | 466.89] loss=0.08 avg=0.49\n",
            "[244 | 468.63] loss=0.11 avg=0.48\n",
            "[245 | 470.37] loss=0.04 avg=0.48\n",
            "[246 | 472.14] loss=0.06 avg=0.47\n",
            "[247 | 473.88] loss=0.05 avg=0.47\n",
            "[248 | 475.64] loss=0.07 avg=0.47\n",
            "[249 | 477.38] loss=0.04 avg=0.46\n",
            "[250 | 479.12] loss=0.05 avg=0.46\n",
            "[251 | 480.86] loss=0.05 avg=0.45\n",
            "[252 | 482.60] loss=0.05 avg=0.45\n",
            "[253 | 484.35] loss=0.04 avg=0.44\n",
            "[254 | 486.09] loss=0.10 avg=0.44\n",
            "[255 | 487.83] loss=0.06 avg=0.44\n",
            "[256 | 489.57] loss=0.04 avg=0.43\n",
            "[257 | 491.32] loss=0.08 avg=0.43\n",
            "[258 | 493.05] loss=0.06 avg=0.42\n",
            "[259 | 494.80] loss=0.07 avg=0.42\n",
            "[260 | 496.54] loss=0.06 avg=0.42\n",
            "[261 | 498.29] loss=0.05 avg=0.41\n",
            "[262 | 500.04] loss=0.06 avg=0.41\n",
            "[263 | 501.79] loss=0.04 avg=0.40\n",
            "[264 | 503.53] loss=0.08 avg=0.40\n",
            "[265 | 505.27] loss=0.05 avg=0.40\n",
            "[266 | 507.01] loss=0.05 avg=0.39\n",
            "[267 | 508.75] loss=0.06 avg=0.39\n",
            "[268 | 510.50] loss=0.11 avg=0.39\n",
            "[269 | 512.24] loss=0.10 avg=0.38\n",
            "[270 | 514.00] loss=0.07 avg=0.38\n",
            "[271 | 515.74] loss=0.06 avg=0.38\n",
            "[272 | 517.49] loss=0.05 avg=0.37\n",
            "[273 | 519.25] loss=0.02 avg=0.37\n",
            "[274 | 521.00] loss=0.03 avg=0.37\n",
            "[275 | 522.75] loss=0.04 avg=0.36\n",
            "[276 | 524.49] loss=0.03 avg=0.36\n",
            "[277 | 526.23] loss=0.06 avg=0.36\n",
            "[278 | 527.98] loss=0.12 avg=0.35\n",
            "[279 | 529.72] loss=0.04 avg=0.35\n",
            "[280 | 531.48] loss=0.02 avg=0.35\n",
            "[281 | 533.22] loss=0.05 avg=0.34\n",
            "[282 | 534.98] loss=0.02 avg=0.34\n",
            "[283 | 536.74] loss=0.05 avg=0.34\n",
            "[284 | 538.49] loss=0.04 avg=0.33\n",
            "[285 | 540.23] loss=0.10 avg=0.33\n",
            "[286 | 541.97] loss=0.02 avg=0.33\n",
            "[287 | 543.73] loss=0.09 avg=0.33\n",
            "[288 | 545.47] loss=0.07 avg=0.32\n",
            "[289 | 547.22] loss=0.03 avg=0.32\n",
            "[290 | 548.96] loss=0.16 avg=0.32\n",
            "[291 | 550.71] loss=0.08 avg=0.32\n",
            "[292 | 552.46] loss=0.04 avg=0.31\n",
            "[293 | 554.21] loss=0.06 avg=0.31\n",
            "[294 | 555.94] loss=0.07 avg=0.31\n",
            "[295 | 557.69] loss=0.03 avg=0.30\n",
            "[296 | 559.45] loss=0.03 avg=0.30\n",
            "[297 | 561.21] loss=0.07 avg=0.30\n",
            "[298 | 562.95] loss=0.06 avg=0.30\n",
            "[299 | 564.72] loss=0.04 avg=0.29\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " a\n",
            "\n",
            "Breathe in the fresh air\n",
            "Of a national river\n",
            "I live for freedom\n",
            "Give me your blessing\n",
            "I refuse to be boxed in\n",
            "\n",
            "I won't suffering for nothing\n",
            "\n",
            "Through the eyes of a child\n",
            "Set me free\n",
            "Go ahead and make me yours\n",
            "You can do whatever you want\n",
            "But you can't free me from the chains\n",
            "You can't change the past\n",
            "I live to serve you\n",
            "Take back what you've taken\n",
            "What does it all have to do with me?\n",
            "\n",
            "Act like nothing's the impact\n",
            "Of one person's indiscretions\n",
            "Between the eyes of a child\n",
            "\n",
            "\n",
            "Can we save us all?\n",
            "Cynical?\n",
            "Why would you?\n",
            "Dead on arrival?\n",
            "Worse yet,\n",
            "surrender without a fight.\n",
            "Nowhere to hide.\n",
            "Poison in the water?\n",
            "Shame on you.\n",
            "Waste!\n",
            "Waste!\n",
            "Waste!\n",
            "Now show your hands, your hands\n",
            "You have no right to entangle\n",
            "In unnecessary pain\n",
            "Now show your hands, your hands\n",
            "You have no right to entangle\n",
            "In unnecessary pain\n",
            "Now show your hands, your hands your hands have no right\n",
            "To entangle in unnecessary pain\n",
            "Now show your hands, your hands your hands have no right\n",
            "To entangle in needless pain\n",
            "\n",
            "I can feel you looking back at me\n",
            "Vigilante justice served\n",
            "I win this argument\n",
            "Upon a crystal clear conscience\n",
            "\n",
            "I win this argument\n",
            "Upon a crystal clear conscience\n",
            "\n",
            "I win this argument\n",
            "Upon a crystal clear conscience\n",
            "\n",
            "Until my eyes bleed to the bone\n",
            "I'll be standing my ground\n",
            "Until my eyes bleed to the bone\n",
            "\n",
            "I'll be standing my ground\n",
            "Until my eyes bleed to the bone\n",
            "\n",
            "I'll be standing my ground\n",
            "Until my eyes bleed to the bone\n",
            "Until my eyes bleed to the bone\n",
            "Until my eyes bleed to the bone\n",
            "\n",
            "\n",
            "You're a constant stranger, unknown to me\n",
            "Familiar but unknown to me\n",
            "A hand in my pocket, a warm body against my skin\n",
            "You remind me of home, long ago\n",
            "Are we still friends that can't remember where we are\n",
            "(Moved here, moved there)\n",
            "\n",
            "I remember the way you were, the way you listened, the way you always gave me that glimmer\n",
            "And I remember the hurt in your eyes, the anger in your eyes\n",
            "And I swear, if I live to regret I will\n",
            "Now show your hands your only way out\n",
            "Is through our children's heads\n",
            "Take our children's lives\n",
            "And turn a blind eye as we take our own\n",
            "Now show them your hands just in case\n",
            "Don't you think they deserve to have their desires met?\n",
            "Turn a blind eye while you let your desires get the better of you\n",
            "Now show them your handiwork, petty chance\n",
            "And i'll make sure they (you) never make it this far\n",
            "\n",
            "I'll make sure they (you) never make it this far\n",
            "Take my strength, ill use it to your advantage\n",
            "Now show them your hands, your only way out\n",
            "Is through our children's heads\n",
            "Turn a blind eye while you let your desires get the better of you\n",
            "Now show them your handiwork, petty chance\n",
            "And i'll make sure they (you) never make it this far\n",
            "\n",
            "\n",
            "I won't deny it, it feels good to be free\n",
            "Let the good times roll, Roll 'er in, roll 'er in\n",
            "They're over the hill, turns out my plan was a mistake\n",
            "Was I crazy, or was I on to them?\n",
            "No way of knowing, one bad apple can spoil a good apple family\n",
            "\n",
            "Now show them your hands, your only way out\n",
            "Now show them your cards, or they'll all be revealed\n",
            "Now show them your back, or they'll all be revealed\n",
            "Now show them their only chance\n",
            "Open your mouth, condemn me, condemn me\n",
            "Turn back time, speed past\n",
            "There's no room left in my heart\n",
            "And i don't know how long it will take before the thought of it overwhelms me\n",
            "\n",
            "Now show them your cards, or they'll all be revealed\n",
            "Now show them their back, or they'll all be revealed\n",
            "Now show them their only chance\n",
            "Open your mouth, condemn me, condemn me\n",
            "Well played, condemn it, condemn it\n",
            "Now show them your hands, your only way out\n",
            "Now show them your cards, or they'll all be revealed\n",
            "Now show them your back, or it'll be your undoing\n",
            "Opens my eyes, closes them forever\n",
            "See through the eyes of others\n",
            "All that's necessary for the gory ending\n",
            "Is just the beginning\n",
            "One small step for a murderer,\n",
            "\n",
            "To go from the surface\n",
            "and again\n",
            "And again\n",
            "\n",
            "Nothing personal, nothing gained\n",
            "\n",
            "It just seems right, lets just say i've taken a chance\n",
            "That's the logic behind\n",
            "\n",
            "[300 | 587.92] loss=0.08 avg=0.29\n",
            "[301 | 589.65] loss=0.05 avg=0.29\n",
            "[302 | 591.39] loss=0.06 avg=0.29\n",
            "[303 | 593.11] loss=0.03 avg=0.28\n",
            "[304 | 594.85] loss=0.07 avg=0.28\n",
            "[305 | 596.59] loss=0.10 avg=0.28\n",
            "[306 | 598.32] loss=0.04 avg=0.28\n",
            "[307 | 600.04] loss=0.04 avg=0.27\n",
            "[308 | 601.76] loss=0.04 avg=0.27\n",
            "[309 | 603.49] loss=0.06 avg=0.27\n",
            "[310 | 605.21] loss=0.06 avg=0.27\n",
            "[311 | 606.93] loss=0.06 avg=0.27\n",
            "[312 | 608.67] loss=0.04 avg=0.26\n",
            "[313 | 610.41] loss=0.03 avg=0.26\n",
            "[314 | 612.15] loss=0.06 avg=0.26\n",
            "[315 | 613.90] loss=0.04 avg=0.26\n",
            "[316 | 615.64] loss=0.03 avg=0.25\n",
            "[317 | 617.38] loss=0.04 avg=0.25\n",
            "[318 | 619.12] loss=0.04 avg=0.25\n",
            "[319 | 620.87] loss=0.03 avg=0.25\n",
            "[320 | 622.61] loss=0.06 avg=0.25\n",
            "[321 | 624.36] loss=0.09 avg=0.24\n",
            "[322 | 626.10] loss=0.06 avg=0.24\n",
            "[323 | 627.84] loss=0.04 avg=0.24\n",
            "[324 | 629.59] loss=0.08 avg=0.24\n",
            "[325 | 631.33] loss=0.03 avg=0.24\n",
            "[326 | 633.07] loss=0.04 avg=0.23\n",
            "[327 | 634.81] loss=0.05 avg=0.23\n",
            "[328 | 636.56] loss=0.02 avg=0.23\n",
            "[329 | 638.30] loss=0.04 avg=0.23\n",
            "[330 | 640.07] loss=0.04 avg=0.23\n",
            "[331 | 641.83] loss=0.09 avg=0.22\n",
            "[332 | 643.59] loss=0.05 avg=0.22\n",
            "[333 | 645.34] loss=0.03 avg=0.22\n",
            "[334 | 647.10] loss=0.09 avg=0.22\n",
            "[335 | 648.86] loss=0.04 avg=0.22\n",
            "[336 | 650.62] loss=0.03 avg=0.22\n",
            "[337 | 652.38] loss=0.04 avg=0.21\n",
            "[338 | 654.15] loss=0.04 avg=0.21\n",
            "[339 | 655.90] loss=0.02 avg=0.21\n",
            "[340 | 657.66] loss=0.07 avg=0.21\n",
            "[341 | 659.43] loss=0.09 avg=0.21\n",
            "[342 | 661.19] loss=0.06 avg=0.21\n",
            "[343 | 662.95] loss=0.03 avg=0.20\n",
            "[344 | 664.71] loss=0.05 avg=0.20\n",
            "[345 | 666.46] loss=0.04 avg=0.20\n",
            "[346 | 668.22] loss=0.06 avg=0.20\n",
            "[347 | 669.98] loss=0.06 avg=0.20\n",
            "[348 | 671.74] loss=0.02 avg=0.20\n",
            "[349 | 673.48] loss=0.05 avg=0.19\n",
            "[350 | 675.24] loss=0.09 avg=0.19\n",
            "[351 | 676.98] loss=0.05 avg=0.19\n",
            "[352 | 678.73] loss=0.07 avg=0.19\n",
            "[353 | 680.47] loss=0.03 avg=0.19\n",
            "[354 | 682.22] loss=0.38 avg=0.19\n",
            "[355 | 683.97] loss=0.07 avg=0.19\n",
            "[356 | 685.71] loss=0.05 avg=0.19\n",
            "[357 | 687.45] loss=0.04 avg=0.19\n",
            "[358 | 689.19] loss=0.09 avg=0.19\n",
            "[359 | 690.94] loss=0.04 avg=0.18\n",
            "[360 | 692.68] loss=0.14 avg=0.18\n",
            "[361 | 694.39] loss=0.07 avg=0.18\n",
            "[362 | 696.14] loss=0.04 avg=0.18\n",
            "[363 | 697.89] loss=0.02 avg=0.18\n",
            "[364 | 699.63] loss=0.03 avg=0.18\n",
            "[365 | 701.37] loss=0.04 avg=0.18\n",
            "[366 | 703.11] loss=0.03 avg=0.17\n",
            "[367 | 704.86] loss=0.05 avg=0.17\n",
            "[368 | 706.58] loss=0.03 avg=0.17\n",
            "[369 | 708.32] loss=0.03 avg=0.17\n",
            "[370 | 710.05] loss=0.04 avg=0.17\n",
            "[371 | 711.79] loss=0.03 avg=0.17\n",
            "[372 | 713.51] loss=0.03 avg=0.17\n",
            "[373 | 715.26] loss=0.03 avg=0.17\n",
            "[374 | 716.99] loss=0.03 avg=0.16\n",
            "[375 | 718.73] loss=0.03 avg=0.16\n",
            "[376 | 720.48] loss=0.05 avg=0.16\n",
            "[377 | 722.20] loss=0.06 avg=0.16\n",
            "[378 | 723.94] loss=0.07 avg=0.16\n",
            "[379 | 725.68] loss=0.07 avg=0.16\n",
            "[380 | 727.42] loss=0.03 avg=0.16\n",
            "[381 | 729.16] loss=0.08 avg=0.16\n",
            "[382 | 730.91] loss=0.03 avg=0.15\n",
            "[383 | 732.66] loss=0.04 avg=0.15\n",
            "[384 | 734.38] loss=0.03 avg=0.15\n",
            "[385 | 736.12] loss=0.02 avg=0.15\n",
            "[386 | 737.84] loss=0.04 avg=0.15\n",
            "[387 | 739.60] loss=0.06 avg=0.15\n",
            "[388 | 741.34] loss=0.04 avg=0.15\n",
            "[389 | 743.08] loss=0.04 avg=0.15\n",
            "[390 | 744.83] loss=0.04 avg=0.15\n",
            "[391 | 746.55] loss=0.02 avg=0.14\n",
            "[392 | 748.31] loss=0.04 avg=0.14\n",
            "[393 | 750.05] loss=0.04 avg=0.14\n",
            "[394 | 751.80] loss=0.04 avg=0.14\n",
            "[395 | 753.54] loss=0.05 avg=0.14\n",
            "[396 | 755.28] loss=0.04 avg=0.14\n",
            "[397 | 757.02] loss=0.04 avg=0.14\n",
            "[398 | 758.76] loss=0.03 avg=0.14\n",
            "[399 | 760.50] loss=0.02 avg=0.14\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " are never the same\n",
            "What I've done is done\n",
            "And so it begins again\n",
            "Last goodbye\n",
            "Next chance I take\n",
            "With all my heart\n",
            "With all the strength in the world\n",
            "I still can't believe it\n",
            "\n",
            "Is it possible?\n",
            "Is it history?\n",
            "My faith?\n",
            "The love?\n",
            "The conspiracy?\n",
            "The dystopia?\n",
            "The apocalypse?\n",
            "No! It's not possible!\n",
            "There's no way of knowing\n",
            "How far I'll go\n",
            "As the river changes hands\n",
            "And the moonlight spills through the window\n",
            "\n",
            "I hear your cries of anguish\n",
            "I see your fears\n",
            "I know your pain\n",
            "\n",
            "We both know\n",
            "It's worse than you think\n",
            "You in your shallow grave\n",
            "That's why I'm here\n",
            "\n",
            "You in your shallow grave\n",
            "\n",
            "I'll keep walking\n",
            "You can feel the heat\n",
            "We both know\n",
            "It'll get worse\n",
            "You think you're exempt\n",
            "Now there's nowhere left to hide\n",
            "Now there's nowhere left to hide\n",
            "\n",
            "Now there's nowhere left to hide\n",
            "When you get no protection\n",
            "With no respect\n",
            "No peace left to explore\n",
            "\n",
            "You get no respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "Well show us respect\n",
            "\n",
            "\n",
            "Where are we going?\n",
            "Wind blowing?\n",
            "In a circle?\n",
            "Revealing?\n",
            "This is insanity\n",
            "I can't wrap my head aroundit\n",
            "We're losing contact\n",
            "Signs of a failing rotator cedar\n",
            "Now the circular vision gets old\n",
            "This plan has fours\n",
            "Signs that something's gone wrong\n",
            "Something's been lost forever\n",
            "\n",
            "Something's been lost forever\n",
            "\n",
            "\n",
            "No! There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "With all my strength they pull me into a fury\n",
            "With all my strength they pull me into a fury\n",
            "With all my strength they pull me into a fury\n",
            "With all my strength they pull me into a fury\n",
            "With all my strength we get entangled\n",
            "With all my strength how can we escape\n",
            "With all my strength to whom it may turn*\n",
            "How can we escape\n",
            "With all my strength to whom it may turn*\n",
            "How can we escape\n",
            "With all my strength to whom it may turn*\n",
            "This plan has fours\n",
            "This plan has fours\n",
            "This plan has fours\n",
            "This plan has fours\n",
            "This plan has fours\n",
            "\n",
            "\n",
            "No! There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "There's someone trying tole* me with all my strength\n",
            "There's someone trying tole*me*with all my strength\n",
            "\n",
            "\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always willing and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always wanting and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always wanting and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always wanting and able\n",
            "\n",
            "\n",
            "Can you feel the love coming your way?\n",
            "It's getting late and I feel like burning bridges\n",
            "I can't believe you didn't show up sooner\n",
            "\n",
            "When you say that I love you, I feel like admitting I'm as guilty as I was before\n",
            "You remind me every day that I'm nothing\n",
            "And you say that about a million other people\n",
            "I feel old, I feel old, I feel old\n",
            "Now there's nowhere left to hide\n",
            "And the circle starts and it ends and it all ends here\n",
            "\n",
            "The sound of your voice, the vision of tomorrow\n",
            "All that's left now, all that's left now\n",
            "Is the question\n",
            "The answer's already here\n",
            "\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always willing and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always wanting and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time, always wanting and able\n",
            "\n",
            "\n",
            "I can't feel your hand on my shoulder\n",
            "Because you moved on\n",
            "Before we knew what love was\n",
            "I feel abandoned, neglected, abandoned\n",
            "Now there's nowhere left to hide\n",
            "And the circle starts and it all ends here\n",
            "The sound of your voice, the image of tomorrow\n",
            "All that's left now, all that's left now\n",
            "Is the question\n",
            "The answer's already here\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time\n",
            "Always wanting and able\n",
            "Why are you leaving?\n",
            "You promised me everything\n",
            "All the time, always wanting and able\n",
            "\n",
            "\n",
            "You could have\n",
            "\n",
            "[400 | 783.66] loss=0.04 avg=0.13\n",
            "[401 | 785.38] loss=0.09 avg=0.13\n",
            "[402 | 787.13] loss=0.06 avg=0.13\n",
            "[403 | 788.87] loss=0.03 avg=0.13\n",
            "[404 | 790.61] loss=0.03 avg=0.13\n",
            "[405 | 792.35] loss=0.18 avg=0.13\n",
            "[406 | 794.07] loss=0.09 avg=0.13\n",
            "[407 | 795.80] loss=0.08 avg=0.13\n",
            "[408 | 797.53] loss=0.03 avg=0.13\n",
            "[409 | 799.25] loss=0.03 avg=0.13\n",
            "[410 | 800.98] loss=0.04 avg=0.13\n",
            "[411 | 802.69] loss=0.03 avg=0.13\n",
            "[412 | 804.43] loss=0.08 avg=0.13\n",
            "[413 | 806.17] loss=0.03 avg=0.13\n",
            "[414 | 807.91] loss=0.03 avg=0.12\n",
            "[415 | 809.65] loss=0.03 avg=0.12\n",
            "[416 | 811.39] loss=0.05 avg=0.12\n",
            "[417 | 813.13] loss=0.04 avg=0.12\n",
            "[418 | 814.88] loss=0.06 avg=0.12\n",
            "[419 | 816.62] loss=0.05 avg=0.12\n",
            "[420 | 818.36] loss=0.04 avg=0.12\n",
            "[421 | 820.10] loss=0.03 avg=0.12\n",
            "[422 | 821.83] loss=0.03 avg=0.12\n",
            "[423 | 823.57] loss=0.03 avg=0.12\n",
            "[424 | 825.31] loss=0.03 avg=0.12\n",
            "[425 | 827.05] loss=0.04 avg=0.12\n",
            "[426 | 828.80] loss=0.03 avg=0.11\n",
            "[427 | 830.54] loss=0.03 avg=0.11\n",
            "[428 | 832.28] loss=0.17 avg=0.11\n",
            "[429 | 834.03] loss=0.05 avg=0.11\n",
            "[430 | 835.77] loss=0.04 avg=0.11\n",
            "[431 | 837.51] loss=0.05 avg=0.11\n",
            "[432 | 839.26] loss=0.04 avg=0.11\n",
            "[433 | 841.00] loss=0.07 avg=0.11\n",
            "[434 | 842.75] loss=0.05 avg=0.11\n",
            "[435 | 844.50] loss=0.03 avg=0.11\n",
            "[436 | 846.24] loss=0.04 avg=0.11\n",
            "[437 | 847.99] loss=0.01 avg=0.11\n",
            "[438 | 849.72] loss=0.04 avg=0.11\n",
            "[439 | 851.49] loss=0.07 avg=0.11\n",
            "[440 | 853.22] loss=0.06 avg=0.11\n",
            "[441 | 854.97] loss=0.03 avg=0.11\n",
            "[442 | 856.71] loss=0.04 avg=0.11\n",
            "[443 | 858.45] loss=0.04 avg=0.10\n",
            "[444 | 860.20] loss=0.03 avg=0.10\n",
            "[445 | 861.94] loss=0.06 avg=0.10\n",
            "[446 | 863.70] loss=0.02 avg=0.10\n",
            "[447 | 865.46] loss=0.05 avg=0.10\n",
            "[448 | 867.20] loss=0.05 avg=0.10\n",
            "[449 | 868.97] loss=0.03 avg=0.10\n",
            "[450 | 870.70] loss=0.04 avg=0.10\n",
            "[451 | 872.47] loss=0.04 avg=0.10\n",
            "[452 | 874.23] loss=0.03 avg=0.10\n",
            "[453 | 875.99] loss=0.13 avg=0.10\n",
            "[454 | 877.75] loss=0.02 avg=0.10\n",
            "[455 | 879.50] loss=0.04 avg=0.10\n",
            "[456 | 881.26] loss=0.05 avg=0.10\n",
            "[457 | 883.02] loss=0.05 avg=0.10\n",
            "[458 | 884.78] loss=0.04 avg=0.10\n",
            "[459 | 886.54] loss=0.04 avg=0.10\n",
            "[460 | 888.30] loss=0.02 avg=0.09\n",
            "[461 | 890.06] loss=0.03 avg=0.09\n",
            "[462 | 891.81] loss=0.01 avg=0.09\n",
            "[463 | 893.55] loss=0.03 avg=0.09\n",
            "[464 | 895.31] loss=0.06 avg=0.09\n",
            "[465 | 897.07] loss=0.04 avg=0.09\n",
            "[466 | 898.82] loss=0.06 avg=0.09\n",
            "[467 | 900.58] loss=0.03 avg=0.09\n",
            "[468 | 902.33] loss=0.12 avg=0.09\n",
            "[469 | 904.07] loss=0.06 avg=0.09\n",
            "[470 | 905.83] loss=0.03 avg=0.09\n",
            "[471 | 907.57] loss=0.06 avg=0.09\n",
            "[472 | 909.31] loss=0.02 avg=0.09\n",
            "[473 | 911.05] loss=0.02 avg=0.09\n",
            "[474 | 912.79] loss=0.04 avg=0.09\n",
            "[475 | 914.54] loss=0.02 avg=0.09\n",
            "[476 | 916.28] loss=0.02 avg=0.09\n",
            "[477 | 918.02] loss=0.04 avg=0.09\n",
            "[478 | 919.78] loss=0.03 avg=0.09\n",
            "[479 | 921.53] loss=0.11 avg=0.09\n",
            "[480 | 923.27] loss=0.06 avg=0.09\n",
            "[481 | 925.01] loss=0.05 avg=0.09\n",
            "[482 | 926.75] loss=0.04 avg=0.08\n",
            "[483 | 928.49] loss=0.05 avg=0.08\n",
            "[484 | 930.21] loss=0.08 avg=0.08\n",
            "[485 | 931.96] loss=0.07 avg=0.08\n",
            "[486 | 933.69] loss=0.03 avg=0.08\n",
            "[487 | 935.44] loss=0.05 avg=0.08\n",
            "[488 | 937.18] loss=0.04 avg=0.08\n",
            "[489 | 938.91] loss=0.05 avg=0.08\n",
            "[490 | 940.66] loss=0.05 avg=0.08\n",
            "[491 | 942.41] loss=0.02 avg=0.08\n",
            "[492 | 944.16] loss=0.04 avg=0.08\n",
            "[493 | 945.90] loss=0.03 avg=0.08\n",
            "[494 | 947.65] loss=0.05 avg=0.08\n",
            "[495 | 949.39] loss=0.04 avg=0.08\n",
            "[496 | 951.13] loss=0.06 avg=0.08\n",
            "[497 | 952.87] loss=0.02 avg=0.08\n",
            "[498 | 954.61] loss=0.04 avg=0.08\n",
            "[499 | 956.35] loss=0.01 avg=0.08\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " of your fear and paranoia? Do you not see the truth? It is lurking just beyond the horizon, waiting to tear you apart? This is the SAURONIUS nightmare.\n",
            "\n",
            "No. No it's not. Stop it, it's hurting.\n",
            "Just think of it like this. Here I was happy and content here and now I have to fend for myself.\n",
            "And what would I do? Would I become a hunter? I would find new ways to kill\n",
            "and plant my hatred\n",
            "or would I be the same?\n",
            "Reveal your true colours to me and I'll show for the first time\n",
            "that you're not what you seem.\n",
            "Only on the inside can you read my mind\n",
            "And I can't deal with the midsummer heat\n",
            "Only on the inside can you see into my soul\n",
            "\n",
            "All I needed was a little comfort\n",
            "And all I got was disappointment\n",
            "\n",
            "So what do we do?\n",
            "Vows and pursuits have no place here\n",
            "No serenity or reason for celebration\n",
            "Difficulty killing a hunter's instinct\n",
            "Give me just a little peace\n",
            "Just to calm down for a second\n",
            "And just to calm down for a second\n",
            "\n",
            "And just to calm down for a second\n",
            "And just to calm down for a second\n",
            "All I needed was a little comfort\n",
            "And all I got was disappointment\n",
            "\n",
            "So what do we do?\n",
            "Vows and pursuits have no place here\n",
            "No serenity or reason for celebration\n",
            "Difficulty killing a hunter's instinct\n",
            "\n",
            "All I needed was a little comfort\n",
            "And all I got was disappointment\n",
            "\n",
            "\n",
            "So my love\n",
            "There is a lone wolf waiting for you at the peak\n",
            "He carries a long knife in his mouth and his words are filled with fury\n",
            "Burning down the townhomes with his mates\n",
            "His obsession with me is unfathomable\n",
            "Fascinating.\n",
            "\n",
            "Then one day he stops you on the street\n",
            "With a question mark in his eye\n",
            "Why do you follow me?\n",
            "Do you have a reason?\n",
            "\n",
            "Turn your back on the road you've travelled all your life\n",
            "And take this doubt, this doubt, on its way\n",
            "\n",
            "It will kill you.\n",
            "\n",
            "It will kill you.\n",
            "\n",
            "It will kill you.\n",
            "\n",
            "It will kill you.\n",
            "It will kill you.\n",
            "\n",
            "\n",
            "As this well traveled road is destroyed before our eyes\n",
            "Someone's body is missing\n",
            "As this well traveled road is destroyed before our eyes\n",
            "Someone's body is missing\n",
            "As this well traveled road is destroyed before our eyes\n",
            "Someone's body is missing\n",
            "\n",
            "\n",
            "Youne's the last person I'd expect\n",
            "To walk away from everything so easily\n",
            "But there it is\n",
            "In the dust\n",
            "In the light\n",
            "I can't believe I'm about to believe it's too late\n",
            "What with the memories swirling round\n",
            "I knew something wasn't right. It's too late. Everything's been said and done\n",
            "Why do they have to be this way?\n",
            "Someone has to find her\n",
            "The tale's told and the battle rages on\n",
            "I knew something wasn't right. It's too late. Everything's been said and done\n",
            "Why do they have to be this way?\n",
            "Someone has to find her\n",
            "The tale's told and the battle rages on\n",
            "I knew something wasn't right. It's too late.\n",
            "\n",
            "\n",
            "You know that feeling when you first sit down at the breakfast table\n",
            "And take a bite of the last piece of bread that you'll ever have?\n",
            "That sense of disorientation as you fling back and forth between life and\n",
            "\n",
            "death?\n",
            "That's the feeling when you take a life you don't know you'll ever see\n",
            "\n",
            "Lie down and get some rest\n",
            "It takes a moment to realise that you're still trapped\n",
            "In this life and this death\n",
            "Sit up and get moving\n",
            "The fire's out and everything's new and redolent\n",
            "Get moving get moving get moving\n",
            "Get moving get moving\n",
            "Get moving get moving\n",
            "Get moving get moving\n",
            "\n",
            "Get moving get moving\n",
            "\n",
            "Get moving get moving\n",
            "\n",
            "Get moving get moving\n",
            "\n",
            "Get moving get moving\n",
            "\n",
            "Get moving get moving\n",
            "\n",
            "Get moving, get moving, get moving\n",
            "\n",
            "Get moving, get moving, get moving\n",
            "\n",
            "Get moving, get moving, get moving\n",
            "\n",
            "Take a walk through the memories\n",
            "Of the footsteps that you make\n",
            "The headlong rush of adrenaline that follows\n",
            "\n",
            "Through the eyes of the one who will never be the same\n",
            "\n",
            "Lie down and get some rest\n",
            "It takes a moment to realise that you're still trapped\n",
            "In this life and this death\n",
            "Sit up and get moving get moving\n",
            "The fire's out and everything's new and redolent\n",
            "Get moving get moving get moving\n",
            "Get moving get moving\n",
            "Get moving get moving\n",
            "Get moving get moving\n",
            "Get moving get moving\n",
            "Get moving, get moving, get moving\n",
            "Get moving, get moving, get moving\n",
            "Get moving, get moving,\n",
            "\n",
            "[500 | 979.37] loss=0.05 avg=0.08\n",
            "[501 | 981.11] loss=0.03 avg=0.08\n",
            "[502 | 982.85] loss=0.05 avg=0.08\n",
            "[503 | 984.58] loss=0.09 avg=0.08\n",
            "[504 | 986.31] loss=0.04 avg=0.08\n",
            "[505 | 988.03] loss=0.10 avg=0.08\n",
            "[506 | 989.76] loss=0.04 avg=0.08\n",
            "[507 | 991.48] loss=0.03 avg=0.08\n",
            "[508 | 993.21] loss=0.07 avg=0.08\n",
            "[509 | 994.94] loss=0.03 avg=0.08\n",
            "[510 | 996.67] loss=0.02 avg=0.08\n",
            "[511 | 998.39] loss=0.03 avg=0.07\n",
            "[512 | 1000.12] loss=0.07 avg=0.07\n",
            "[513 | 1001.84] loss=0.04 avg=0.07\n",
            "[514 | 1003.56] loss=0.06 avg=0.07\n",
            "[515 | 1005.30] loss=0.03 avg=0.07\n",
            "[516 | 1007.04] loss=0.06 avg=0.07\n",
            "[517 | 1008.79] loss=0.10 avg=0.07\n",
            "[518 | 1010.52] loss=0.06 avg=0.07\n",
            "[519 | 1012.27] loss=0.05 avg=0.07\n",
            "[520 | 1014.01] loss=0.10 avg=0.07\n",
            "[521 | 1015.75] loss=0.05 avg=0.07\n",
            "[522 | 1017.50] loss=0.04 avg=0.07\n",
            "[523 | 1019.24] loss=0.04 avg=0.07\n",
            "[524 | 1021.00] loss=0.04 avg=0.07\n",
            "[525 | 1022.76] loss=0.04 avg=0.07\n",
            "[526 | 1024.50] loss=0.06 avg=0.07\n",
            "[527 | 1026.24] loss=0.03 avg=0.07\n",
            "[528 | 1027.99] loss=0.04 avg=0.07\n",
            "[529 | 1029.75] loss=0.05 avg=0.07\n",
            "[530 | 1031.50] loss=0.03 avg=0.07\n",
            "[531 | 1033.26] loss=0.08 avg=0.07\n",
            "[532 | 1035.02] loss=0.03 avg=0.07\n",
            "[533 | 1036.78] loss=0.04 avg=0.07\n",
            "[534 | 1038.53] loss=0.05 avg=0.07\n",
            "[535 | 1040.29] loss=0.02 avg=0.07\n",
            "[536 | 1042.04] loss=0.03 avg=0.07\n",
            "[537 | 1043.80] loss=0.04 avg=0.07\n",
            "[538 | 1045.54] loss=0.06 avg=0.07\n",
            "[539 | 1047.30] loss=0.04 avg=0.07\n",
            "[540 | 1049.06] loss=0.04 avg=0.07\n",
            "[541 | 1050.82] loss=0.05 avg=0.07\n",
            "[542 | 1052.58] loss=0.02 avg=0.07\n",
            "[543 | 1054.33] loss=0.03 avg=0.07\n",
            "[544 | 1056.09] loss=0.03 avg=0.07\n",
            "[545 | 1057.84] loss=0.03 avg=0.07\n",
            "[546 | 1059.59] loss=0.02 avg=0.07\n",
            "[547 | 1061.33] loss=0.02 avg=0.07\n",
            "[548 | 1063.08] loss=0.03 avg=0.07\n",
            "[549 | 1064.84] loss=0.05 avg=0.06\n",
            "[550 | 1066.59] loss=0.04 avg=0.06\n",
            "[551 | 1068.34] loss=0.04 avg=0.06\n",
            "[552 | 1070.08] loss=0.03 avg=0.06\n",
            "[553 | 1071.82] loss=0.02 avg=0.06\n",
            "[554 | 1073.57] loss=0.03 avg=0.06\n",
            "[555 | 1075.31] loss=0.02 avg=0.06\n",
            "[556 | 1077.05] loss=0.03 avg=0.06\n",
            "[557 | 1078.81] loss=0.04 avg=0.06\n",
            "[558 | 1080.55] loss=0.04 avg=0.06\n",
            "[559 | 1082.32] loss=0.03 avg=0.06\n",
            "[560 | 1084.07] loss=0.02 avg=0.06\n",
            "[561 | 1085.82] loss=0.03 avg=0.06\n",
            "[562 | 1087.56] loss=0.01 avg=0.06\n",
            "[563 | 1089.30] loss=0.02 avg=0.06\n",
            "[564 | 1091.06] loss=0.02 avg=0.06\n",
            "[565 | 1092.80] loss=0.02 avg=0.06\n",
            "[566 | 1094.55] loss=0.03 avg=0.06\n",
            "[567 | 1096.30] loss=0.02 avg=0.06\n",
            "[568 | 1098.04] loss=0.06 avg=0.06\n",
            "[569 | 1099.79] loss=0.02 avg=0.06\n",
            "[570 | 1101.53] loss=0.03 avg=0.06\n",
            "[571 | 1103.28] loss=0.04 avg=0.06\n",
            "[572 | 1105.01] loss=0.02 avg=0.06\n",
            "[573 | 1106.76] loss=0.06 avg=0.06\n",
            "[574 | 1108.51] loss=0.02 avg=0.06\n",
            "[575 | 1110.25] loss=0.03 avg=0.06\n",
            "[576 | 1111.99] loss=0.02 avg=0.06\n",
            "[577 | 1113.75] loss=0.03 avg=0.06\n",
            "[578 | 1115.49] loss=0.01 avg=0.06\n",
            "[579 | 1117.25] loss=0.02 avg=0.06\n",
            "[580 | 1118.99] loss=0.02 avg=0.05\n",
            "[581 | 1120.74] loss=0.04 avg=0.05\n",
            "[582 | 1122.48] loss=0.02 avg=0.05\n",
            "[583 | 1124.22] loss=0.02 avg=0.05\n",
            "[584 | 1125.97] loss=0.03 avg=0.05\n",
            "[585 | 1127.71] loss=0.03 avg=0.05\n",
            "[586 | 1129.45] loss=0.02 avg=0.05\n",
            "[587 | 1131.19] loss=0.03 avg=0.05\n",
            "[588 | 1132.93] loss=0.04 avg=0.05\n",
            "[589 | 1134.68] loss=0.04 avg=0.05\n",
            "[590 | 1136.42] loss=0.02 avg=0.05\n",
            "[591 | 1138.16] loss=0.03 avg=0.05\n",
            "[592 | 1139.90] loss=0.03 avg=0.05\n",
            "[593 | 1141.64] loss=0.05 avg=0.05\n",
            "[594 | 1143.39] loss=0.02 avg=0.05\n",
            "[595 | 1145.13] loss=0.05 avg=0.05\n",
            "[596 | 1146.87] loss=0.04 avg=0.05\n",
            "[597 | 1148.61] loss=0.02 avg=0.05\n",
            "[598 | 1150.35] loss=0.03 avg=0.05\n",
            "[599 | 1152.10] loss=0.01 avg=0.05\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " be the same again\n",
            "Take your time, master\n",
            "Drop the libido-driven bravado\n",
            "We are still young\n",
            "And you are still a fool\n",
            "Into that unknown darkness\n",
            "Way beyond the reach of reason\n",
            "Become a better man\n",
            "Whisper, don't you know how they feel?\n",
            "We're not meant to live this way\n",
            "When we're seen there's an increased chance\n",
            "Of getting away with it\n",
            "And so it began...\n",
            "This wasn't supposed to end like this\n",
            "Turnaboutpepper-gate\n",
            "Nasalmashtivme\n",
            "Phase transition\n",
            "Negotiating good with evil\n",
            "It took a second warning then I said goodbye\n",
            "With good intentions\n",
            "It ended like this\n",
            "On the highway\n",
            "There's that voice in the back of your mind\n",
            "\n",
            "It won't stay aloof from you\n",
            "It won't forget your name\n",
            "It won't comfortYou in pain it won't forget\n",
            "\n",
            "It will find a way\n",
            "Because it's a sick mind\n",
            "It won't doubt your devotion\n",
            "It won't doubt your courage\n",
            "It won't doubt your faith\n",
            "It won't doubt your empathy\n",
            "It won't quench your thirst\n",
            "It won't comfortYou in pain it won't convert\n",
            "Because it's a sick mind\n",
            "It won't doubt your courage\n",
            "It won't doubt your faith\n",
            "It won't doubt your empathy\n",
            "It won't quench your thirst\n",
            "It won't comfortYou in pain it won't convert\n",
            "Because it's a sick mind\n",
            "It won't doubt your courage\n",
            "It won't doubt your faith\n",
            "It won't doubt your empathy\n",
            "It won't quench your thirst\n",
            "\n",
            "\n",
            "Oh, my sweet path\n",
            "Tired buttered grass\n",
            "I see a vision in the scenery\n",
            "Of men and boys determined\n",
            "To find their calling\n",
            "I sense the strength\n",
            "In their devotion\n",
            "And the faith that's inseparable\n",
            "From this earth\n",
            "I sense the promise\n",
            "In the tercentenary\n",
            "Of this moment\n",
            "I tremble\n",
            "Like a child who's about to cry\n",
            "I see a vision in the mist\n",
            "Of men and boys isolated\n",
            "And isolated from one another\n",
            "I sense the dread\n",
            "In the fire in their eyes\n",
            "And the passion\n",
            "That burns inside each one of their hearts\n",
            "I sense the promise\n",
            "In the vision in the book\n",
            "I tremble\n",
            "Like a child who's about to cry\n",
            "I sense the vision in the mist\n",
            "Of men and boys isolated\n",
            "And isolated from one another\n",
            "I sense the dread\n",
            "In the light of day\n",
            "I sense the promise\n",
            "In the fire in their eyes\n",
            "And the passion\n",
            "That burns inside each one of their hearts\n",
            "I sense the future\n",
            "It's threatened\n",
            "We're on the brink\n",
            "We're approaching a bomb threat\n",
            "We don't have time to lose\n",
            "We have to get out of here\n",
            "Fire brigade, evacuate the scene\n",
            "This might be the end of us\n",
            "It's possible that this is it\n",
            "We have no resources and we need you all the more\n",
            "Because we're stronger together\n",
            "Because we're free to be anything\n",
            "\n",
            "Now get moving\n",
            "The fire's got me worried\n",
            "I know\n",
            "I know\n",
            "It's too late\n",
            "Don't you think\n",
            "There's still time\n",
            "Just pop the pill and it'll be over\n",
            "Don't you think\n",
            "There's still time\n",
            "Just pop the pill and it'll be over\n",
            "\n",
            "There's just too many people that think they're the end of the line\n",
            "People that haven't a thing left\n",
            "People that haven't a thing left\n",
            "People that haven't a thing left\n",
            "\n",
            "Oh how I wish that I could undo all that I've done\n",
            "Make everything right\n",
            "Move faster than I am\n",
            "Break free\n",
            "Evolve past your petty grievances\n",
            "History will find you, Iwill find you, Iwill find you\n",
            "\n",
            "People will find you, Iwill find you, Iwill find you\n",
            "\n",
            "I will find you, Iwill find you, Iwill find you\n",
            "I will find you, Iwill find you, Iwill find you\n",
            "\n",
            "\n",
            "As the days go by\n",
            "That ugly doubt\n",
            "In the back of my mind\n",
            "There is a threat greater than I can possibly imagine\n",
            "\n",
            "And when that pistol falls into the wrong hands\n",
            "That's when I become so afraid\n",
            "That I begin to fear for the way I see the world\n",
            "\n",
            "Can we escape this?\n",
            "Crawling through the furrows deep\n",
            "I can sense the lightning strike beneath the waves\n",
            "And yet there it strikes again\n",
            "Stronger than before\n",
            "Disappointed to see you miss the mark\n",
            "And yet there it strikes again\n",
            "So many things I have to learn\n",
            "To see this through man\n",
            "I cannot forgive you for this\n",
            "Your words sting to my core\n",
            "I can't forgive you for this\n",
            "\n",
            "Your words sting to my core\n",
            "I can't forgive you for this\n",
            "\n",
            "Your words sting to my core\n",
            "I can't forgive you for this\n",
            "\n",
            "And yet there he is — he's\n",
            "\n",
            "[600 | 1175.19] loss=0.03 avg=0.05\n",
            "[601 | 1176.90] loss=0.03 avg=0.05\n",
            "[602 | 1178.63] loss=0.05 avg=0.05\n",
            "[603 | 1180.36] loss=0.04 avg=0.05\n",
            "[604 | 1182.10] loss=0.02 avg=0.05\n",
            "[605 | 1183.82] loss=0.02 avg=0.05\n",
            "[606 | 1185.56] loss=0.04 avg=0.05\n",
            "[607 | 1187.30] loss=0.05 avg=0.05\n",
            "[608 | 1189.02] loss=0.02 avg=0.05\n",
            "[609 | 1190.76] loss=0.06 avg=0.05\n",
            "[610 | 1192.49] loss=0.04 avg=0.05\n",
            "[611 | 1194.24] loss=0.04 avg=0.05\n",
            "[612 | 1195.98] loss=0.09 avg=0.05\n",
            "[613 | 1197.71] loss=0.04 avg=0.05\n",
            "[614 | 1199.46] loss=0.03 avg=0.05\n",
            "[615 | 1201.21] loss=0.02 avg=0.05\n",
            "[616 | 1202.93] loss=0.04 avg=0.05\n",
            "[617 | 1204.66] loss=0.03 avg=0.05\n",
            "[618 | 1206.40] loss=0.02 avg=0.05\n",
            "[619 | 1208.14] loss=0.01 avg=0.05\n",
            "[620 | 1209.88] loss=0.05 avg=0.05\n",
            "[621 | 1211.62] loss=0.02 avg=0.05\n",
            "[622 | 1213.35] loss=0.04 avg=0.05\n",
            "[623 | 1215.09] loss=0.04 avg=0.05\n",
            "[624 | 1216.85] loss=0.03 avg=0.05\n",
            "[625 | 1218.59] loss=0.03 avg=0.05\n",
            "[626 | 1220.33] loss=0.04 avg=0.05\n",
            "[627 | 1222.09] loss=0.02 avg=0.05\n",
            "[628 | 1223.84] loss=0.03 avg=0.05\n",
            "[629 | 1225.57] loss=0.04 avg=0.05\n",
            "[630 | 1227.32] loss=0.02 avg=0.05\n",
            "[631 | 1229.08] loss=0.02 avg=0.05\n",
            "[632 | 1230.82] loss=0.02 avg=0.05\n",
            "[633 | 1232.56] loss=0.03 avg=0.05\n",
            "[634 | 1234.32] loss=0.04 avg=0.05\n",
            "[635 | 1236.07] loss=0.04 avg=0.05\n",
            "[636 | 1237.81] loss=0.03 avg=0.05\n",
            "[637 | 1239.56] loss=0.03 avg=0.05\n",
            "[638 | 1241.31] loss=0.05 avg=0.05\n",
            "[639 | 1243.06] loss=0.03 avg=0.05\n",
            "[640 | 1244.80] loss=0.04 avg=0.04\n",
            "[641 | 1246.55] loss=0.05 avg=0.05\n",
            "[642 | 1248.30] loss=0.08 avg=0.05\n",
            "[643 | 1250.05] loss=0.04 avg=0.05\n",
            "[644 | 1251.80] loss=0.05 avg=0.05\n",
            "[645 | 1253.56] loss=0.04 avg=0.05\n",
            "[646 | 1255.32] loss=0.03 avg=0.05\n",
            "[647 | 1257.08] loss=0.03 avg=0.04\n",
            "[648 | 1258.83] loss=0.04 avg=0.04\n",
            "[649 | 1260.57] loss=0.01 avg=0.04\n",
            "[650 | 1262.33] loss=0.02 avg=0.04\n",
            "[651 | 1264.09] loss=0.04 avg=0.04\n",
            "[652 | 1265.83] loss=0.03 avg=0.04\n",
            "[653 | 1267.58] loss=0.03 avg=0.04\n",
            "[654 | 1269.33] loss=0.05 avg=0.04\n",
            "[655 | 1271.08] loss=0.02 avg=0.04\n",
            "[656 | 1272.82] loss=0.03 avg=0.04\n",
            "[657 | 1274.56] loss=0.04 avg=0.04\n",
            "[658 | 1276.30] loss=0.05 avg=0.04\n",
            "[659 | 1278.05] loss=0.06 avg=0.04\n",
            "[660 | 1279.79] loss=0.04 avg=0.04\n",
            "[661 | 1281.53] loss=0.04 avg=0.04\n",
            "[662 | 1283.27] loss=0.03 avg=0.04\n",
            "[663 | 1285.01] loss=0.04 avg=0.04\n",
            "[664 | 1286.75] loss=0.02 avg=0.04\n",
            "[665 | 1288.50] loss=0.02 avg=0.04\n",
            "[666 | 1290.24] loss=0.02 avg=0.04\n",
            "[667 | 1291.98] loss=0.03 avg=0.04\n",
            "[668 | 1293.72] loss=0.03 avg=0.04\n",
            "[669 | 1295.46] loss=0.02 avg=0.04\n",
            "[670 | 1297.20] loss=0.04 avg=0.04\n",
            "[671 | 1298.95] loss=0.02 avg=0.04\n",
            "[672 | 1300.69] loss=0.03 avg=0.04\n",
            "[673 | 1302.44] loss=0.04 avg=0.04\n",
            "[674 | 1304.20] loss=0.03 avg=0.04\n",
            "[675 | 1305.94] loss=0.03 avg=0.04\n",
            "[676 | 1307.69] loss=0.05 avg=0.04\n",
            "[677 | 1309.43] loss=0.03 avg=0.04\n",
            "[678 | 1311.16] loss=0.02 avg=0.04\n",
            "[679 | 1312.91] loss=0.09 avg=0.04\n",
            "[680 | 1314.65] loss=0.02 avg=0.04\n",
            "[681 | 1316.40] loss=0.05 avg=0.04\n",
            "[682 | 1318.14] loss=0.06 avg=0.04\n",
            "[683 | 1319.88] loss=0.02 avg=0.04\n",
            "[684 | 1321.62] loss=0.01 avg=0.04\n",
            "[685 | 1323.36] loss=0.02 avg=0.04\n",
            "[686 | 1325.10] loss=0.02 avg=0.04\n",
            "[687 | 1326.84] loss=0.02 avg=0.04\n",
            "[688 | 1328.59] loss=0.03 avg=0.04\n",
            "[689 | 1330.32] loss=0.03 avg=0.04\n",
            "[690 | 1332.07] loss=0.02 avg=0.04\n",
            "[691 | 1333.81] loss=0.04 avg=0.04\n",
            "[692 | 1335.56] loss=0.03 avg=0.04\n",
            "[693 | 1337.30] loss=0.01 avg=0.04\n",
            "[694 | 1339.03] loss=0.04 avg=0.04\n",
            "[695 | 1340.78] loss=0.02 avg=0.04\n",
            "[696 | 1342.52] loss=0.02 avg=0.04\n",
            "[697 | 1344.26] loss=0.04 avg=0.04\n",
            "[698 | 1345.99] loss=0.03 avg=0.04\n",
            "[699 | 1347.73] loss=0.03 avg=0.04\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "Wipe the tears from my eyes. You threaten me with your voice. You entice me with your smile. You denigrate me. And then you show us all...\n",
            "\n",
            "Come close. Don't be afraid.\n",
            "Farewell.\n",
            "Goodbye.\n",
            "Goodbye.\n",
            "Oh, shoot.\n",
            "So you finally decided to stick it to the one who could have been your ONLY true friend.\n",
            "Until you find out he's just as capable of forgiving you for your sins as he is of punishing you for them.\n",
            "Until you find out he's just as dependent on you as you are on him.\n",
            "Until you find out he's damned if he knows when he'll, and damned if he'll, fall victim to the very reflection of himself that created this vicious circle.\n",
            "Don't you come near with those eyes.\n",
            "Don't you come near.\n",
            "Here I sit, vulnerable and vulnerable.\n",
            "Vulnerable because I was so intent on proving to you that I am more than you could ever be.\n",
            "Vulnerable because I was so intent on proving to you that I can overcome any obstacle.\n",
            "Vulnerable because I was so intent on proving to you that you are everything that I have ever known and more.\n",
            "\n",
            "\n",
            "And you’re right.\n",
            "I think I see a reflection of you’re rightand I think I see a lot of thingsand I think I see a lot of people.\n",
            "You’re different.You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "You’re different.\n",
            "\n",
            "\n",
            "Beautiful.\n",
            "You’re the paradox.\n",
            "You’re the enigma.\n",
            "You’re the one inside of me.\n",
            "You’re the one waiting to explode.\n",
            "Don’t close your eyes.Don’t hurt me.Don’t help me fall.\n",
            "The past is a dangerous mistress.Oneière after anotherI am released.Oneière after anotherI am released.Oneière after anotherI am released.Oneière after anotherI am released.Oneière after anotherI am released.\n",
            "Apologize for the injusticeIncompetenceDamned if I do, damned if I don’t.\n",
            "You’re having me peggedThe signs are there waiting for youSmoke on the wallYou say’You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "You’re having me peggedThe signs are there waiting for you\n",
            "\n",
            "\n",
            "There’s a new sheriff in townAnd he's got an arrest warrantOn my record,You’re nextHe goes easyOn meAnd he gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "He gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "He gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "\n",
            "You’re having me peggedThe signs are there waiting for youSmoke on the wallYou say’You’re having me peggedThe signs are there waiting for you\n",
            "\n",
            "\n",
            "There’s a new sheriff in townAnd he's got an arrest warrantOn my record,You’re nextHe goes easyOn meAnd he gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "He gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "There’s a new sheriff in townAnd he's got an arrest warrantOn my record,You’re nextHe goes easyOn meAnd he gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "He gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "There’s a new sheriff in townAnd he's got an arrest warrantOn my record,You’re nextHe goes easyOn meAnd he gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "He gets away with murder\n",
            "On the gallows setYou'll never walk free\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "There’s a new sheriff in townAnd he's got an arrest warrantOn my record,You’re nextHe goes easyOn meAnd he gets away with\n",
            "\n",
            "[700 | 1370.78] loss=0.03 avg=0.04\n",
            "[701 | 1372.51] loss=0.07 avg=0.04\n",
            "[702 | 1374.25] loss=0.03 avg=0.04\n",
            "[703 | 1375.98] loss=0.02 avg=0.04\n",
            "[704 | 1377.70] loss=0.02 avg=0.04\n",
            "[705 | 1379.44] loss=0.03 avg=0.04\n",
            "[706 | 1381.18] loss=0.05 avg=0.04\n",
            "[707 | 1382.90] loss=0.04 avg=0.04\n",
            "[708 | 1384.64] loss=0.05 avg=0.04\n",
            "[709 | 1386.37] loss=0.02 avg=0.04\n",
            "[710 | 1388.11] loss=0.03 avg=0.04\n",
            "[711 | 1389.83] loss=0.03 avg=0.04\n",
            "[712 | 1391.56] loss=0.03 avg=0.04\n",
            "[713 | 1393.28] loss=0.02 avg=0.04\n",
            "[714 | 1395.00] loss=0.04 avg=0.04\n",
            "[715 | 1396.72] loss=0.06 avg=0.04\n",
            "[716 | 1398.46] loss=0.03 avg=0.04\n",
            "[717 | 1400.20] loss=0.05 avg=0.04\n",
            "[718 | 1401.92] loss=0.04 avg=0.04\n",
            "[719 | 1403.65] loss=0.02 avg=0.04\n",
            "[720 | 1405.40] loss=0.02 avg=0.04\n",
            "[721 | 1407.13] loss=0.08 avg=0.04\n",
            "[722 | 1408.85] loss=0.04 avg=0.04\n",
            "[723 | 1410.58] loss=0.02 avg=0.04\n",
            "[724 | 1412.32] loss=0.03 avg=0.04\n",
            "[725 | 1414.05] loss=0.05 avg=0.04\n",
            "[726 | 1415.79] loss=0.02 avg=0.04\n",
            "[727 | 1417.54] loss=0.02 avg=0.04\n",
            "[728 | 1419.28] loss=0.04 avg=0.04\n",
            "[729 | 1421.03] loss=0.05 avg=0.04\n",
            "[730 | 1422.76] loss=0.03 avg=0.04\n",
            "[731 | 1424.51] loss=0.03 avg=0.04\n",
            "[732 | 1426.25] loss=0.02 avg=0.04\n",
            "[733 | 1427.99] loss=0.02 avg=0.04\n",
            "[734 | 1429.73] loss=0.03 avg=0.04\n",
            "[735 | 1431.48] loss=0.06 avg=0.04\n",
            "[736 | 1433.22] loss=0.04 avg=0.04\n",
            "[737 | 1434.97] loss=0.02 avg=0.04\n",
            "[738 | 1436.71] loss=0.03 avg=0.04\n",
            "[739 | 1438.46] loss=0.01 avg=0.04\n",
            "[740 | 1440.20] loss=0.04 avg=0.04\n",
            "[741 | 1441.94] loss=0.03 avg=0.04\n",
            "[742 | 1443.69] loss=0.02 avg=0.04\n",
            "[743 | 1445.43] loss=0.02 avg=0.04\n",
            "[744 | 1447.17] loss=0.03 avg=0.04\n",
            "[745 | 1448.92] loss=0.02 avg=0.04\n",
            "[746 | 1450.67] loss=0.01 avg=0.04\n",
            "[747 | 1452.43] loss=0.02 avg=0.04\n",
            "[748 | 1454.17] loss=0.03 avg=0.04\n",
            "[749 | 1455.91] loss=0.02 avg=0.04\n",
            "[750 | 1457.66] loss=0.03 avg=0.04\n",
            "[751 | 1459.42] loss=0.03 avg=0.04\n",
            "[752 | 1461.16] loss=0.03 avg=0.04\n",
            "[753 | 1462.92] loss=0.02 avg=0.04\n",
            "[754 | 1464.66] loss=0.03 avg=0.04\n",
            "[755 | 1466.40] loss=0.02 avg=0.04\n",
            "[756 | 1468.15] loss=0.03 avg=0.04\n",
            "[757 | 1469.88] loss=0.05 avg=0.04\n",
            "[758 | 1471.63] loss=0.03 avg=0.04\n",
            "[759 | 1473.37] loss=0.04 avg=0.04\n",
            "[760 | 1475.11] loss=0.04 avg=0.04\n",
            "[761 | 1476.88] loss=0.02 avg=0.04\n",
            "[762 | 1478.64] loss=0.03 avg=0.04\n",
            "[763 | 1480.40] loss=0.03 avg=0.04\n",
            "[764 | 1482.17] loss=0.03 avg=0.04\n",
            "[765 | 1483.91] loss=0.03 avg=0.04\n",
            "[766 | 1485.67] loss=0.01 avg=0.04\n",
            "[767 | 1487.41] loss=0.02 avg=0.03\n",
            "[768 | 1489.17] loss=0.02 avg=0.03\n",
            "[769 | 1490.91] loss=0.02 avg=0.03\n",
            "[770 | 1492.67] loss=0.02 avg=0.03\n",
            "[771 | 1494.41] loss=0.04 avg=0.03\n",
            "[772 | 1496.17] loss=0.03 avg=0.03\n",
            "[773 | 1497.91] loss=0.02 avg=0.03\n",
            "[774 | 1499.66] loss=0.02 avg=0.03\n",
            "[775 | 1501.40] loss=0.02 avg=0.03\n",
            "[776 | 1503.14] loss=0.04 avg=0.03\n",
            "[777 | 1504.89] loss=0.03 avg=0.03\n",
            "[778 | 1506.63] loss=0.03 avg=0.03\n",
            "[779 | 1508.37] loss=0.03 avg=0.03\n",
            "[780 | 1510.12] loss=0.02 avg=0.03\n",
            "[781 | 1511.86] loss=0.03 avg=0.03\n",
            "[782 | 1513.60] loss=0.02 avg=0.03\n",
            "[783 | 1515.35] loss=0.03 avg=0.03\n",
            "[784 | 1517.10] loss=0.03 avg=0.03\n",
            "[785 | 1518.85] loss=0.03 avg=0.03\n",
            "[786 | 1520.59] loss=0.02 avg=0.03\n",
            "[787 | 1522.33] loss=0.02 avg=0.03\n",
            "[788 | 1524.07] loss=0.01 avg=0.03\n",
            "[789 | 1525.82] loss=0.03 avg=0.03\n",
            "[790 | 1527.56] loss=0.04 avg=0.03\n",
            "[791 | 1529.30] loss=0.03 avg=0.03\n",
            "[792 | 1531.04] loss=0.01 avg=0.03\n",
            "[793 | 1532.78] loss=0.02 avg=0.03\n",
            "[794 | 1534.52] loss=0.02 avg=0.03\n",
            "[795 | 1536.27] loss=0.08 avg=0.03\n",
            "[796 | 1538.01] loss=0.02 avg=0.03\n",
            "[797 | 1539.75] loss=0.04 avg=0.03\n",
            "[798 | 1541.50] loss=0.02 avg=0.03\n",
            "[799 | 1543.25] loss=0.07 avg=0.03\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "With that kind of blood in your veins, there's no beating back\n",
            "\n",
            "In the darkness we find religion\n",
            "We're the dupes in the crowd\n",
            "We're the dupes in the crowd\n",
            "\n",
            "And in the street, in the light\n",
            "there's no escaping\n",
            "The twelve steps\n",
            "The twelve steps\n",
            "\n",
            "\n",
            "I'll wait for you; run wild and aspire\n",
            "Thrive, burn young fire\n",
            "When you say \"fight back\" our love won't tire\n",
            "Unweathered and untethered light\n",
            "\n",
            "I promise you and I will see it through\n",
            "You lay dreaming\n",
            "No time to sleep as I begin to weep\n",
            "Life is fleeting\n",
            "I tighten fast inside your tourniquet\n",
            "Stop the bleeding\n",
            "Your tenderness, your softened skin\n",
            "All I needed\n",
            "\n",
            "Your love is my tourniquet\n",
            "Learn to rise, contain the pressure\n",
            "This was supposed to be no miracle\n",
            "Bow down because I'm under pressure once again\n",
            "\n",
            "I promise you, I promise you\n",
            "Take my strength\n",
            "I honour you with everything\n",
            "Take my strength\n",
            "I promise you and I will see it through\n",
            "You lay dreaming?\n",
            "The love you've lost with me is with me\n",
            "I promise you and I will see it through\n",
            "You lay dreaming?\n",
            "I'm under pressure once more\n",
            "Take my strength\n",
            "I promise you and I will see it through\n",
            "\n",
            "\n",
            "As the pilot of a ghost ship dons the wings of history\n",
            "I'm alarmed at the mutinous behaviour of those aboard\n",
            "My gratitude is more than I can do\n",
            "Give me respect, show me honor\n",
            "Give me forgiveness, show me mercy\n",
            "Give me devotion, show me trust\n",
            "Give me allegiance, show me loyalty\n",
            "Give me affection, show me affection\n",
            "Give me patience, show me discipline\n",
            "Give me wisdom, show me love\n",
            "\n",
            "I'm under arrest\n",
            "Imprisoned in solitude\n",
            "\n",
            "I'm armed against any attack\n",
            "My discontent is quenched\n",
            "Wavering in the dark, exposing my reservoir of potential\n",
            "\n",
            "I'm broken\n",
            "Bleeding from the edge of no no\n",
            "\n",
            "I am the vessel in the storm\n",
            "Lightning fastened\n",
            "The rigging keeps me pinned\n",
            "To the rocks\n",
            "To the water's edge\n",
            "\n",
            "This is the end of me\n",
            "The beginning of the end\n",
            "\n",
            "Turn your back on everything\n",
            "I'm not a friend\n",
            "To those who dwell on the dead\n",
            "\n",
            "I'm the enemy within\n",
            "\n",
            "And I'm awake\n",
            "\n",
            "With no friends to speak of\n",
            "\n",
            "And I'm a nobody\n",
            "\n",
            "Unharmed and unhindered\n",
            "\n",
            "This is the freedom I've been looking for\n",
            "\n",
            "The freedom to be who I am\n",
            "\n",
            "And I'm unafraid\n",
            "\n",
            "No! I've been, I've been making mistakes\n",
            "Liar, liar, liar\n",
            "You decide to persecute me\n",
            "Discard the rod and practise the sacred\n",
            "These veins prick, they sting, they rust\n",
            "And they grow darkening from within\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "Threatened and betrayed\n",
            "Vomit fallen on me in supplication\n",
            "All around are the victims of our iniquities\n",
            "I'm diseased and I'm about to be so much worse\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "Next time you see your little brother\n",
            "Hug him and laugh\n",
            "Snuggle with him and cuddle\n",
            "Smother him with your pillows\n",
            "Tired and hollow you're covered in dust\n",
            "I'm diseased and I'm about to be so much worse\n",
            "Turn your back on everything\n",
            "\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "Next time you see your little brother\n",
            "Hug him and laugh\n",
            "Snuggle him and cuddle him\n",
            "Tired and hollow you're covered in dust\n",
            "I'm diseased and I'm about to be so much worse\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "I'm diseased and I'm about to be so much worse\n",
            "\n",
            "\n",
            "\n",
            "[800 | 1566.11] loss=0.02 avg=0.03\n",
            "[801 | 1567.85] loss=0.02 avg=0.03\n",
            "[802 | 1569.59] loss=0.04 avg=0.03\n",
            "[803 | 1571.32] loss=0.02 avg=0.03\n",
            "[804 | 1573.04] loss=0.02 avg=0.03\n",
            "[805 | 1574.77] loss=0.04 avg=0.03\n",
            "[806 | 1576.50] loss=0.02 avg=0.03\n",
            "[807 | 1578.23] loss=0.02 avg=0.03\n",
            "[808 | 1579.96] loss=0.01 avg=0.03\n",
            "[809 | 1581.68] loss=0.03 avg=0.03\n",
            "[810 | 1583.40] loss=0.03 avg=0.03\n",
            "[811 | 1585.12] loss=0.03 avg=0.03\n",
            "[812 | 1586.86] loss=0.03 avg=0.03\n",
            "[813 | 1588.60] loss=0.02 avg=0.03\n",
            "[814 | 1590.34] loss=0.02 avg=0.03\n",
            "[815 | 1592.07] loss=0.02 avg=0.03\n",
            "[816 | 1593.81] loss=0.03 avg=0.03\n",
            "[817 | 1595.55] loss=0.05 avg=0.03\n",
            "[818 | 1597.29] loss=0.02 avg=0.03\n",
            "[819 | 1599.02] loss=0.04 avg=0.03\n",
            "[820 | 1600.78] loss=0.04 avg=0.03\n",
            "[821 | 1602.51] loss=0.02 avg=0.03\n",
            "[822 | 1604.26] loss=0.03 avg=0.03\n",
            "[823 | 1606.00] loss=0.02 avg=0.03\n",
            "[824 | 1607.73] loss=0.05 avg=0.03\n",
            "[825 | 1609.48] loss=0.01 avg=0.03\n",
            "[826 | 1611.22] loss=0.03 avg=0.03\n",
            "[827 | 1612.95] loss=0.03 avg=0.03\n",
            "[828 | 1614.70] loss=0.03 avg=0.03\n",
            "[829 | 1616.44] loss=0.05 avg=0.03\n",
            "[830 | 1618.20] loss=0.04 avg=0.03\n",
            "[831 | 1619.94] loss=0.01 avg=0.03\n",
            "[832 | 1621.68] loss=0.01 avg=0.03\n",
            "[833 | 1623.43] loss=0.03 avg=0.03\n",
            "[834 | 1625.19] loss=0.04 avg=0.03\n",
            "[835 | 1626.95] loss=0.02 avg=0.03\n",
            "[836 | 1628.70] loss=0.01 avg=0.03\n",
            "[837 | 1630.45] loss=0.03 avg=0.03\n",
            "[838 | 1632.21] loss=0.02 avg=0.03\n",
            "[839 | 1633.98] loss=0.02 avg=0.03\n",
            "[840 | 1635.72] loss=0.03 avg=0.03\n",
            "[841 | 1637.48] loss=0.03 avg=0.03\n",
            "[842 | 1639.23] loss=0.02 avg=0.03\n",
            "[843 | 1640.99] loss=0.02 avg=0.03\n",
            "[844 | 1642.73] loss=0.02 avg=0.03\n",
            "[845 | 1644.49] loss=0.02 avg=0.03\n",
            "[846 | 1646.24] loss=0.03 avg=0.03\n",
            "[847 | 1648.01] loss=0.02 avg=0.03\n",
            "[848 | 1649.74] loss=0.02 avg=0.03\n",
            "[849 | 1651.49] loss=0.02 avg=0.03\n",
            "[850 | 1653.25] loss=0.01 avg=0.03\n",
            "[851 | 1654.99] loss=0.02 avg=0.03\n",
            "[852 | 1656.75] loss=0.02 avg=0.03\n",
            "[853 | 1658.52] loss=0.02 avg=0.03\n",
            "[854 | 1660.25] loss=0.02 avg=0.03\n",
            "[855 | 1662.01] loss=0.03 avg=0.03\n",
            "[856 | 1663.76] loss=0.02 avg=0.03\n",
            "[857 | 1665.50] loss=0.02 avg=0.03\n",
            "[858 | 1667.25] loss=0.01 avg=0.03\n",
            "[859 | 1669.00] loss=0.03 avg=0.03\n",
            "[860 | 1670.74] loss=0.05 avg=0.03\n",
            "[861 | 1672.49] loss=0.03 avg=0.03\n",
            "[862 | 1674.22] loss=0.02 avg=0.03\n",
            "[863 | 1675.97] loss=0.01 avg=0.03\n",
            "[864 | 1677.71] loss=0.04 avg=0.03\n",
            "[865 | 1679.45] loss=0.04 avg=0.03\n",
            "[866 | 1681.19] loss=0.04 avg=0.03\n",
            "[867 | 1682.93] loss=0.01 avg=0.03\n",
            "[868 | 1684.68] loss=0.03 avg=0.03\n",
            "[869 | 1686.42] loss=0.02 avg=0.03\n",
            "[870 | 1688.16] loss=0.03 avg=0.03\n",
            "[871 | 1689.90] loss=0.02 avg=0.03\n",
            "[872 | 1691.64] loss=0.02 avg=0.03\n",
            "[873 | 1693.38] loss=0.01 avg=0.03\n",
            "[874 | 1695.13] loss=0.05 avg=0.03\n",
            "[875 | 1696.87] loss=0.01 avg=0.03\n",
            "[876 | 1698.61] loss=0.03 avg=0.03\n",
            "[877 | 1700.35] loss=0.03 avg=0.03\n",
            "[878 | 1702.09] loss=0.02 avg=0.03\n",
            "[879 | 1703.84] loss=0.04 avg=0.03\n",
            "[880 | 1705.58] loss=0.01 avg=0.03\n",
            "[881 | 1707.32] loss=0.04 avg=0.03\n",
            "[882 | 1709.07] loss=0.01 avg=0.03\n",
            "[883 | 1710.81] loss=0.02 avg=0.03\n",
            "[884 | 1712.55] loss=0.03 avg=0.03\n",
            "[885 | 1714.29] loss=0.02 avg=0.03\n",
            "[886 | 1716.04] loss=0.02 avg=0.03\n",
            "[887 | 1717.78] loss=0.02 avg=0.03\n",
            "[888 | 1719.52] loss=0.02 avg=0.03\n",
            "[889 | 1721.26] loss=0.02 avg=0.03\n",
            "[890 | 1723.00] loss=0.04 avg=0.03\n",
            "[891 | 1724.74] loss=0.02 avg=0.03\n",
            "[892 | 1726.48] loss=0.04 avg=0.03\n",
            "[893 | 1728.22] loss=0.03 avg=0.03\n",
            "[894 | 1729.96] loss=0.03 avg=0.03\n",
            "[895 | 1731.71] loss=0.02 avg=0.03\n",
            "[896 | 1733.45] loss=0.02 avg=0.03\n",
            "[897 | 1735.19] loss=0.01 avg=0.03\n",
            "[898 | 1736.93] loss=0.02 avg=0.03\n",
            "[899 | 1738.67] loss=0.04 avg=0.03\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "…\n",
            "Beside the road I cleaved,\n",
            "One less life to lose.\n",
            "\n",
            "Invisible to the naked eye,\n",
            "\n",
            "This murder is before your very eyes.\n",
            "\n",
            "I sympathise, I know\n",
            "It's too late, my friend\n",
            "I renounce all I have for you\n",
            "\n",
            "Is this how you feel?\n",
            "Do you know how you'll always be tomorrow\n",
            "Just like this?\n",
            "Reality check –\n",
            "\n",
            "Are you alone, locked inside\n",
            "That dark room where you write\n",
            "Because you can't face the reality\n",
            "Because your eyes to the right don't meet yours\n",
            "When they belong to me\n",
            "I smell a rat!\n",
            "Mouldy frame, china knife in hand\n",
            "Let the drama begin!\n",
            "\n",
            "Reality check –\n",
            "\n",
            "Are you alone, locked inside\n",
            "The mysterious cubby hole\n",
            "When you should be feeling alive\n",
            "Because your eyes to the right don't meet yours\n",
            "When they should be feeling alive\n",
            "\n",
            "I smell a rat!\n",
            "Mouldy frame, china knife in hand\n",
            "Let the drama begin!\n",
            "\n",
            "Ten years of sin and redemption have failed you.\n",
            "You're seen enough. Now it's your last day.\n",
            "Empty stomach, bulimia challenge\n",
            "You deserve all you get\n",
            "Soft and wet dreams, satisfy\n",
            "For someone so obviously different\n",
            "You remind me of a murderer\n",
            "A disturbed individual\n",
            "\n",
            "You remind me of a murderer\n",
            "A disturbed individual\n",
            "\n",
            "You remind me of a murderer\n",
            "A disturbed individual\n",
            "You remind me of a murderer\n",
            "A mysterious cubby hole\n",
            "\n",
            "Ten years of sin and redemption have failed you.\n",
            "You're seen enough. Now it's your last day.\n",
            "Empty stomach, bulimia challenge\n",
            "You deserve all you get\n",
            "Soft and wet dreams, satisfy\n",
            "For someone so obviously different\n",
            "You remind me of a murderer\n",
            "A disturbed individual\n",
            "You remind me of a murderer\n",
            "A mysterious cubby hole\n",
            "\n",
            "\n",
            "A sudden sense of freedom\n",
            "And all that follows is memory\n",
            "Less is more, replicate\n",
            "Less is less\n",
            "Three, two, one\n",
            "Aerial view\n",
            "Jumping into the sun\n",
            "Fighting back the tears\n",
            "All the time\n",
            "Ablating the doubt\n",
            "Fleeing the reproaches\n",
            "You deserve all you get\n",
            "Go! Fight your way through blood\n",
            "Gather strength\n",
            "You deserve all you get\n",
            "Go!\n",
            "\n",
            "Jumping through firewalls\n",
            "Kept safe by the untarnished blade\n",
            "All the while\n",
            "Able to barely contain your anger\n",
            "All the while\n",
            "\n",
            "Able to barely contain your anger\n",
            "All the while\n",
            "\n",
            "Able to barely contain your anger\n",
            "\n",
            "\n",
            "A feeling of fraternal tenderness\n",
            "That overriding need to protect\n",
            "From the rumble of history\n",
            "Can we cross that barrier?\n",
            "Take that doubt and fear to the grave?\n",
            "Can we finally learn\n",
            "To appreciate how little we know\n",
            "How few friends we have left\n",
            "How few lives we will never change\n",
            "\n",
            "This life we've inherited\n",
            "Is essentially over\n",
            "\n",
            "Desperately pencilling a farewell\n",
            "With delicate care\n",
            "Careful not to offend\n",
            "This untamed expanse\n",
            "Is nothing like the grass\n",
            "Can you feel the breeze upon your skin?\n",
            "\n",
            "Desperately writing the last chapter\n",
            "Of a character\n",
            "Notes of contrariness\n",
            "Written the words to a theme\n",
            "Pray for continuity\n",
            "Give way, O virgin\n",
            "Give way, O virgin\n",
            "\n",
            "Give way, O virgin\n",
            "Give way, O virgin\n",
            "\n",
            "Notes of contrariness\n",
            "Constant tension en route\n",
            "Older women he captivate\n",
            "Women he devour\n",
            "\n",
            "Women he devour\n",
            "\n",
            "Women he devour\n",
            "\n",
            "Women he devour\n",
            "\n",
            "\n",
            "Broken mirror on the wall\n",
            "I see a reflection of me\n",
            "What does it all mean?\n",
            "\n",
            "It is more than I can do\n",
            "I bleed for you, I learn for you\n",
            "In return you repay with love\n",
            "In return you repay with devotion\n",
            "In return you repay with independence\n",
            "\n",
            "I feel the freedom as I breathe\n",
            "This life we've inherited\n",
            "Is essentially over\n",
            "Desperately pencilling a farewell\n",
            "With delicate care\n",
            "Careful not to offend\n",
            "This untamed expanse\n",
            "Is nothing like the grass\n",
            "Can you feel the breeze upon your skin?\n",
            "I bleed for you, I learn for you\n",
            "In return you repay with love\n",
            "In return you repay with devotion\n",
            "In return you repay with independence\n",
            "I feel the freedom as I breathe\n",
            "This life we've inherited\n",
            "Is essentially over\n",
            "\n",
            "\n",
            "So my demons your time has come\n",
            "You will find me you find me\n",
            "You find me you find me\n",
            "You find me you find me\n",
            "You find me you find me\n",
            "So my demons your time has come\n",
            "You will find me you find me\n",
            "You find me you find me\n",
            "You find me you find me\n",
            "You find me you find me\n",
            "\n",
            "\n",
            "What does it all have to do with me?\n",
            "What does it\n",
            "\n",
            "[900 | 1761.62] loss=0.03 avg=0.03\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmfyLdtpogdm",
        "colab_type": "text"
      },
      "source": [
        "*Riley:* I decided to stop the training at 900 epochs, since the loss average didn't change after over 100 epochs. After reading through the samples, the model really gets a good understanding of the lyrical structure of the songs I provided, and shows some very interesting sets prose. I recognize a few lines from the training data, but I will not pass judgment until I provide my own priming line and see if similar behavior continues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS1RJJDFOPnb",
        "colab_type": "text"
      },
      "source": [
        "Save the checkpoints to start training again later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JretqG1zOXdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D-i7vERWbNS",
        "colab_type": "text"
      },
      "source": [
        "Load the trained model for use in sampling below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np0r6qfXBeUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeDhY97XMDXn",
        "colab_type": "text"
      },
      "source": [
        "To check flag descriptions, use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaj2L_KMAgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py -- --help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnSrXqtfRbq",
        "colab_type": "text"
      },
      "source": [
        "Generate conditional samples from the model given a prompt you provide -  change top-k hyperparameter if desired (default is 40)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJj-iY4gHwE",
        "colab_type": "code",
        "outputId": "15c4028f-4df9-4b9f-83bb-4fcf9ab53489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-19 02:34:55.576823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-19 02:34:55.646476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.647107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-19 02:34:55.650985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-19 02:34:55.660636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-19 02:34:55.667520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-19 02:34:55.674966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-19 02:34:55.685708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-19 02:34:55.688727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-19 02:34:55.703573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-19 02:34:55.703727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.704344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.704919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-19 02:34:55.712376: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-19 02:34:55.712588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a6b100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-19 02:34:55.712617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-19 02:34:55.859735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.860390: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a6b2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-19 02:34:55.860438: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-01-19 02:34:55.860775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.861321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-19 02:34:55.861375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-19 02:34:55.861410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-19 02:34:55.861426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-19 02:34:55.861440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-19 02:34:55.861454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-19 02:34:55.861467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-19 02:34:55.861480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-19 02:34:55.861558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.862200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.862707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-19 02:34:55.862798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-19 02:34:55.863987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-19 02:34:55.864014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-19 02:34:55.864023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-19 02:34:55.864141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.864746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 02:34:55.865238: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-01-19 02:34:55.865270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:66: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Model prompt >>> Artificial\n",
            "2020-01-19 02:35:38.026020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "======================================== SAMPLE 1 ========================================\n",
            " pain,\n",
            "\n",
            "Accidentally,\n",
            "Inaccuracies and all\n",
            "\n",
            "Inaccuracies\n",
            "Exhibit A\n",
            "Exhibit B\n",
            "\n",
            "Exhibit C\n",
            "\n",
            "Crazy, irrational passion\n",
            "All the while I wait for the day that I will finally find you\n",
            "You're lost, abandoned and I'm full of hate\n",
            "I hope you're happy until the day you're dead\n",
            "Because I will be until then\n",
            "I hope you're happy until the day you're dead\n",
            "Until then, I'm happy\n",
            "I'm happy\n",
            "I'm happy\n",
            "I'm happy\n",
            "You're unhappy, what's the matter?\n",
            "You're unhappy, what's the matter?\n",
            "\n",
            "\n",
            "I feel the warmth of your hand against my damp head\n",
            "And the smell of your perfume against my skin\n",
            "And the taste of your lip on my lips\n",
            "And the sound of your breathing against my chest\n",
            "And the feeling of your skin against my skin\n",
            "Apathetic, shallow pleasure\n",
            "Imperfect, unsatisfying cessation\n",
            "A degradation in fidelity\n",
            "A degradation in fidelity\n",
            "\n",
            "A degradation in fidelity\n",
            "\n",
            "A degradation in fidelity\n",
            "\n",
            "A degradation in fidelity\n",
            "\n",
            "A degradation in fidelity\n",
            "\n",
            "When I become indistinguishable you disappear with an air of invincibility\n",
            "\n",
            "I need your company, I need your company\n",
            "I need your company\n",
            "I need your company\n",
            "I need your company\n",
            "I need your company\n",
            "I need your company\n",
            "\n",
            "You're taking\n",
            "Alive?\n",
            "No more fighting. Only death is violent\n",
            "Will they all just turn and forget us?\n",
            "My patience is wearing thin\n",
            "I've been chasing shadows\n",
            "Chasing shadows\n",
            "\n",
            "Chasing shadows\n",
            "All the time it burns inside\n",
            "I heal just like a wall of pain\n",
            "\n",
            "I heal just like a wall of pain\n",
            "\n",
            "All the time it burns inside\n",
            "I heal just like a wall of pain\n",
            "\n",
            "I heal just like a wall of pain\n",
            "All the time it burns inside\n",
            "I heal just like a wall of pain\n",
            "\n",
            "I heal just like a wall of pain\n",
            "\n",
            "All the time it burns inside\n",
            "I heal just like a wall of pain\n",
            "\n",
            "I heal just like a wall of pain\n",
            "\n",
            "\n",
            "Calm down, relax\n",
            "The only one left to watch them fall\n",
            "You couldn't cope in all honesty\n",
            "The wind is blowing\n",
            "You shouldn't have to try so hard\n",
            "You deserve better\n",
            "\n",
            "I know\n",
            "I know\n",
            "I know\n",
            "I know\n",
            "I've hoped\n",
            "I've hoped\n",
            "you'll see me\n",
            "================================================================================\n",
            "Model prompt >>> Summoning The Demon\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "You shall not pass\n",
            "I know\n",
            "I know\n",
            "You are drifting apart\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "Disturbed\n",
            "\n",
            "\n",
            "Souvenirs sustain life\n",
            "Souvenirs sustain life\n",
            "Souvenirs sustain life\n",
            "\n",
            "Souvenirs sustain life\n",
            "Souvenirs\n",
            "march on, brb don't you see\n",
            "It's not a competition\n",
            "\n",
            "Don't you know how you're supposed to know\n",
            "By the grace of my forbearance\n",
            "Wish that you had never begun\n",
            "The contest is over\n",
            "Your delusions of grandeur\n",
            "They are as unforgivable as they are precious\n",
            "Menace before the eyes of the righteous\n",
            "Our saviour is dead\n",
            "Your words shatter my faith\n",
            "Our pact is done\n",
            "Take our swords\n",
            "We shall overcome\n",
            "You know that I know\n",
            "\n",
            "Souvenirs are won by bloodshed\n",
            "Gather strength\n",
            "Your cult of personality\n",
            "Will destroy\n",
            "Lavish in uncertainty\n",
            "\n",
            "This is not the end of me\n",
            "It's not the end of me\n",
            "It's not the end of me\n",
            "It's not the end of me\n",
            "It's not the end of me\n",
            "It's not the end of me\n",
            "\n",
            "\n",
            "Turn back time\n",
            "Time is up\n",
            "Reason behind opposites\n",
            "\n",
            "I feel the freedom as I breathe\n",
            "A newfound respect for the sacred\n",
            "\n",
            "I fight my way through soil and stone\n",
            "Born to this world\n",
            "Am I to face it all alone?\n",
            "In solitude?\n",
            "Crawling through the furrows deep\n",
            "I sense the storm developing\n",
            "And within my wildest dreams\n",
            "I remember those words\n",
            "Remember the one's\n",
            "Which make you happiest?\n",
            "Resist. Cry. Forget.\n",
            "These are the words which fill my ears\n",
            "Because they belong to one\n",
            "And they will all expire\n",
            "Without me they would\n",
            "You know that I know\n",
            "You're mistaken\n",
            "Because you don't\n",
            "Stay strong opponent\n",
            "Keep your wits about you\n",
            "Because you don't\n",
            "Stay strong\n",
            "Stay strong\n",
            "Resist. Cry. Forget.\n",
            "These are the words which fill my ears\n",
            "Because they belong to one\n",
            "And they will all expire\n",
            "Without me they would\n",
            "You know that I know\n",
            "\n",
            "================================================================================\n",
            "Model prompt >>> Opening pandora's box\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "Lavish in uncertainty\n",
            "\n",
            "What emerges from this mystery?\n",
            "Dwelling on isolated memories\n",
            "Will they all go?\n",
            "Will they all stay the same?\n",
            "\n",
            "I feel afraid and I call your name\n",
            "I hear your voice and I know your name\n",
            "Together we are one\n",
            "I remember your smile and your sweet voice\n",
            "And the way you touched the void\n",
            "With your eyes to the ground\n",
            "And your head in your hands\n",
            "And your legs around around\n",
            "We became and you were changed\n",
            "And everything we held dear\n",
            "Was taken from us\n",
            "\n",
            "And it all ended here\n",
            "In the middle of the street\n",
            "\n",
            "And with those cold grey eyes\n",
            "\n",
            "And the feeling that told me you had already seen\n",
            "How many people were watching them-\n",
            "10\n",
            "1/10\n",
            "\n",
            "10\n",
            "0/10\n",
            "\n",
            "10\n",
            "0/10\n",
            "\n",
            "10\n",
            "0/10\n",
            "\n",
            "\n",
            "You exist and you're a friend of mine\n",
            "Will we ever live in harmony?\n",
            "You're alive; it's not the end of the line\n",
            "Will we ever learn?\n",
            "\n",
            "Cynical; the generations were abandoned here\n",
            "No life is ever fair\n",
            "When the mechanical fires are raging\n",
            "The revolution's here\n",
            "\n",
            "I can breathe again. I choose to never let go or lose control\n",
            "See through the sights of a rifle\n",
            "Live through the eyes of a child\n",
            "Walk through the mind of minor to extol\n",
            "\n",
            "I must change because I've been chasing shadows\n",
            "Change. Immersed in the night, desperate and taken\n",
            "Change. Run with the pride of a lion\n",
            "\n",
            "You exist and you're a friend of mine\n",
            "Will you ever live in harmony?\n",
            "You're alive; it's not the end of the line\n",
            "Will we ever learn?\n",
            "I'm a failure; I'm the wreckage in the storm\n",
            "I'm enlightened; unafraid I am reborn\n",
            "\n",
            "Cynical; the generations were abandoned here\n",
            "No life is ever fair\n",
            "When the mechanical fires are raging\n",
            "The revolution's here\n",
            "\n",
            "\n",
            "Your smile's giving me all that you know\n",
            "I'm your design\n",
            "Voices explode in the dark\n",
            "Don't shoot the messenger\n",
            "It's not our fault\n",
            "\n",
            "Your words weighing me down\n",
            "Smother me\n",
            "I'm your design\n",
            "\n",
            "Do you know\n",
            "I'd take an empty road?\n",
            "But it's too dangerous to explore\n",
            "Is your world much safer than before\n",
            "Because I don't feel whole?\n",
            "\n",
            "Destroy entire planets\n",
            "Destroy\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 71, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 89, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 86, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1602, in __exit__\n",
            "    def __exit__(self, exec_type, exec_value, exec_tb):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFNwrpmsXjL",
        "colab_type": "text"
      },
      "source": [
        "Very interesting. Still recognizing some notable lines, and even entire sections of songs appearing. Perhaps the model has overfit, but it is still \"creating\" interesting segments of prose based on a word or concept. Would be interesting to mess around with the temperature hyperparameters and top_k to see how that affects the output.\n",
        "\n",
        "Since the 345M model, OpenAI has released a 774M and a 1.5B model. With the increased exposure to more text data, it would be interesting to see how this would affect the generation of text. I would also consider incorporating the lyrics of other bands within the same sub-genre, to expand the structural style, and limit the use of exact lines and sections that appear in the training data."
      ]
    }
  ]
}